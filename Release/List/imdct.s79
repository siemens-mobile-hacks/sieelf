//////////////////////////////////////////////////////////////////////////////
//                                                                           /
// IAR ARM ANSI C/C++ Compiler V4.42A/W32 EVALUATION   13/Aug/2008  18:45:27 /
// Copyright 1999-2005 IAR Systems. All rights reserved.                     /
//                                                                           /
//    Cpu mode        =  interwork                                           /
//    Endian          =  little                                              /
//    Stack alignment =  4                                                   /
//    Source file     =  G:\Arm\SieELF\cbn_SRC\MP3Player\mp3dec\imdct.c      /
//    Command line    =  G:\Arm\SieELF\cbn_SRC\MP3Player\mp3dec\imdct.c -lC  /
//                       G:\Arm\SieELF\cbn_SRC\MP3Player\Release\List\ -lA   /
//                       G:\Arm\SieELF\cbn_SRC\MP3Player\Release\List\ -o    /
//                       G:\Arm\SieELF\cbn_SRC\MP3Player\Release\Obj\ -s9    /
//                       --no_unroll --cpu_mode arm --endian little --cpu    /
//                       ARM926EJ-S --stack_align 4 --interwork -e           /
//                       --char_is_signed --fpu None -I                      /
//                       D:\ewarm_442\arm\INC\ --inline_threshold=2          /
//    List file       =  G:\Arm\SieELF\cbn_SRC\MP3Player\Release\List\imdct. /
//                       s79                                                 /
//                                                                           /
//                                                                           /
//////////////////////////////////////////////////////////////////////////////

        NAME imdct

        RTMODEL "StackAlign4", "USED"
        RTMODEL "__cpu_mode", "__pcs__interwork"
        RTMODEL "__data_model", "absolute"
        RTMODEL "__endian", "little"
        RTMODEL "__rt_version", "6"

        RSEG CSTACK:DATA:NOROOT(2)

??DataTable0 EQU 0
??DataTable1 EQU 0
??DataTable2 EQU 0
        MULTWEAK ??MULSHIFT32??rA
        MULTWEAK ??xmp3_IMDCT??rT
        FUNCTION AntiAlias,0203H
        LOCFRAME CSTACK, 44, STACK
        FUNCTION FreqInvertRescale,0203H
        LOCFRAME CSTACK, 24, STACK
        FUNCTION HybridTransform,0203H
        LOCFRAME CSTACK, 124, STACK
        FUNCTION IMDCT12x3,0203H
        LOCFRAME CSTACK, 228, STACK
        FUNCTION IMDCT36,0203H
        LOCFRAME CSTACK, 196, STACK
        FUNCTION WinPrevious,0203H
        LOCFRAME CSTACK, 36, STACK
c3_0    EQU 0
`c6`    EQU 0
c9_0    EQU 0
c9_1    EQU 0
c9_2    EQU 0
c9_3    EQU 0
c9_4    EQU 0
        FUNCTION idct9,0203H
        LOCFRAME CSTACK, 64, STACK
        FUNCTION imdct12,0203H
        LOCFRAME CSTACK, 36, STACK
        PUBLIC xmp3_IMDCT
        FUNCTION xmp3_IMDCT,0203H
        LOCFRAME CSTACK, 76, STACK
        
        CFI Names cfiNames0
        CFI StackFrame CFA R13 HUGEDATA
        CFI Resource R0:32, R1:32, R2:32, R3:32, R4:32, R5:32, R6:32, R7:32
        CFI Resource R8:32, R9:32, R10:32, R11:32, R12:32, CPSR:32, R13:32
        CFI Resource R14:32, SPSR:32
        CFI VirtualResource ?RET:32
        CFI EndNames cfiNames0
        
        CFI Common cfiCommon0 Using cfiNames0
        CFI CodeAlign 2
        CFI DataAlign 4
        CFI ReturnAddress ?RET CODE
        CFI CFA R13+0
        CFI R0 Undefined
        CFI R1 Undefined
        CFI R2 Undefined
        CFI R3 Undefined
        CFI R4 SameValue
        CFI R5 SameValue
        CFI R6 SameValue
        CFI R7 SameValue
        CFI R8 SameValue
        CFI R9 SameValue
        CFI R10 SameValue
        CFI R11 SameValue
        CFI R12 Undefined
        CFI CPSR SameValue
        CFI R14 Undefined
        CFI SPSR SameValue
        CFI ?RET R14
        CFI EndCommon cfiCommon0
        
        
        CFI Common cfiCommon1 Using cfiNames0
        CFI CodeAlign 4
        CFI DataAlign 4
        CFI ReturnAddress ?RET CODE
        CFI CFA R13+0
        CFI R0 Undefined
        CFI R1 Undefined
        CFI R2 Undefined
        CFI R3 Undefined
        CFI R4 SameValue
        CFI R5 SameValue
        CFI R6 SameValue
        CFI R7 SameValue
        CFI R8 SameValue
        CFI R9 SameValue
        CFI R10 SameValue
        CFI R11 SameValue
        CFI R12 Undefined
        CFI CPSR SameValue
        CFI R14 Undefined
        CFI SPSR SameValue
        CFI ?RET R14
        CFI EndCommon cfiCommon1
        
MULSHIFT32          SYMBOL "MULSHIFT32"
??MULSHIFT32??rA    SYMBOL "??rA", MULSHIFT32
xmp3_IMDCT          SYMBOL "xmp3_IMDCT"
??xmp3_IMDCT??rT    SYMBOL "??rT", xmp3_IMDCT

        EXTERN MULSHIFT32
        FUNCTION MULSHIFT32,0202H
        EXTERN xmp3_csa
        EXTERN xmp3_imdctWin


        RSEG CODE:CODE:NOROOT(2)
        CFI Block cfiBlock0 Using cfiCommon0
        CFI NoFunction
        THUMB
??AntiAlias??rT:
        BX       PC
        Nop      
        CFI EndBlock cfiBlock0
        REQUIRE AntiAlias
// G:\Arm\SieELF\cbn_SRC\MP3Player\mp3dec\imdct.c
//    1 /* ***** BEGIN LICENSE BLOCK *****
//    2  * Version: RCSL 1.0/RPSL 1.0
//    3  *
//    4  * Portions Copyright (c) 1995-2002 RealNetworks, Inc. All Rights Reserved.
//    5  *
//    6  * The contents of this file, and the files included with this file, are
//    7  * subject to the current version of the RealNetworks Public Source License
//    8  * Version 1.0 (the "RPSL") available at
//    9  * http://www.helixcommunity.org/content/rpsl unless you have licensed
//   10  * the file under the RealNetworks Community Source License Version 1.0
//   11  * (the "RCSL") available at http://www.helixcommunity.org/content/rcsl,
//   12  * in which case the RCSL will apply. You may also obtain the license terms
//   13  * directly from RealNetworks.  You may not use this file except in
//   14  * compliance with the RPSL or, if you have a valid RCSL with RealNetworks
//   15  * applicable to this file, the RCSL.  Please see the applicable RPSL or
//   16  * RCSL for the rights, obligations and limitations governing use of the
//   17  * contents of the file.
//   18  *
//   19  * This file is part of the Helix DNA Technology. RealNetworks is the
//   20  * developer of the Original Code and owns the copyrights in the portions
//   21  * it created.
//   22  *
//   23  * This file, and the files included with this file, is distributed and made
//   24  * available on an 'AS IS' basis, WITHOUT WARRANTY OF ANY KIND, EITHER
//   25  * EXPRESS OR IMPLIED, AND REALNETWORKS HEREBY DISCLAIMS ALL SUCH WARRANTIES,
//   26  * INCLUDING WITHOUT LIMITATION, ANY WARRANTIES OF MERCHANTABILITY, FITNESS
//   27  * FOR A PARTICULAR PURPOSE, QUIET ENJOYMENT OR NON-INFRINGEMENT.
//   28  *
//   29  * Technology Compatibility Kit Test Suite(s) Location:
//   30  *    http://www.helixcommunity.org/content/tck
//   31  *
//   32  * Contributor(s):
//   33  *
//   34  * ***** END LICENSE BLOCK ***** */
//   35 
//   36 /**************************************************************************************
//   37  * Fixed-point MP3 decoder
//   38  * Jon Recker (jrecker@real.com), Ken Cooke (kenc@real.com)
//   39  * June 2003
//   40  *
//   41  * imdct.c - antialias, inverse transform (short/long/mixed), windowing,
//   42  *             overlap-add, frequency inversion
//   43  **************************************************************************************/
//   44 
//   45 #include "coder.h"
//   46 #include "assembly.h"
//   47 
//   48 /**************************************************************************************
//   49  * Function:    AntiAlias
//   50  *
//   51  * Description: smooth transition across DCT block boundaries (every 18 coefficients)
//   52  *
//   53  * Inputs:      vector of dequantized coefficients, length = (nBfly+1) * 18
//   54  *              number of "butterflies" to perform (one butterfly means one
//   55  *                inter-block smoothing operation)
//   56  *
//   57  * Outputs:     updated coefficient vector x
//   58  *
//   59  * Return:      none
//   60  *
//   61  * Notes:       weighted average of opposite bands (pairwise) from the 8 samples
//   62  *                before and after each block boundary
//   63  *              nBlocks = (nonZeroBound + 7) / 18, since nZB is the first ZERO sample
//   64  *                above which all other samples are also zero
//   65  *              max gain per sample = 1.372
//   66  *                MAX(i) (abs(csa[i][0]) + abs(csa[i][1]))
//   67  *              bits gained = 0
//   68  *              assume at least 1 guard bit in x[] to avoid overflow
//   69  *                (should be guaranteed from dequant, and max gain from stproc * max
//   70  *                 gain from AntiAlias < 2.0)
//   71  **************************************************************************************/

        RSEG CODE:CODE:NOROOT(2)
        CFI Block cfiBlock1 Using cfiCommon1
        CFI Function AntiAlias
        ARM
//   72 static void AntiAlias(int *x, int nBfly)
//   73 {
AntiAlias:
        PUSH     {R4-R11,LR}
        CFI ?RET Frame(CFA, -4)
        CFI R11 Frame(CFA, -8)
        CFI R10 Frame(CFA, -12)
        CFI R9 Frame(CFA, -16)
        CFI R8 Frame(CFA, -20)
        CFI R7 Frame(CFA, -24)
        CFI R6 Frame(CFA, -28)
        CFI R5 Frame(CFA, -32)
        CFI R4 Frame(CFA, -36)
        CFI CFA R13+36
        SUB      SP,SP,#+8
        CFI CFA R13+44
        MOV      R4,R0
//   74 	int k, a0, b0, c0, c1;
//   75 	const int *c;
//   76 
//   77 	/* csa = Q31 */
//   78 	for (k = nBfly; k > 0; k--) {
        STR      R1,[SP, #+0]
        CMP      R1,#+1
        POPLT    {R0,R1,R4-R11,PC}
        LDR      R5,??AntiAlias_0  ;; xmp3_csa
        LDR      R1,[R5, #+4]
        STR      R1,[SP, #+4]
//   79 		c = csa[0];
//   80 		x += 18;
//   81 
//   82 		a0 = x[-1];			c0 = *c;	c++;	b0 = x[0];		c1 = *c;	c++;
??AntiAlias_1:
        LDR      R9,[R5, #+0]
        LDR      R8,[SP, #+4]
        ADD      R4,R4,#+72
        LDR      R7,[R4, #-4]
        LDR      R10,[R4, #+0]
//   83 		x[-1] = (MULSHIFT32(c0, a0) - MULSHIFT32(c1, b0)) << 1;
        MOV      R1,R7
        MOV      R0,R9
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        MOV      R11,R0
        SUB      R6,R4,#+32
        MOV      R1,R10
        MOV      R0,R8
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        SUB      R0,R11,R0
        LSL      R0,R0,#+1
        STR      R0,[R6, #+28]
//   84 		x[0] =  (MULSHIFT32(c0, b0) + MULSHIFT32(c1, a0)) << 1;
        MOV      R1,R10
        MOV      R0,R9
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        MOV      R9,R0
        MOV      R1,R7
        MOV      R0,R8
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        ADD      R0,R0,R9
        LSL      R0,R0,#+1
        STR      R0,[R4, #+0]
//   85 
//   86 		a0 = x[-2];			c0 = *c;	c++;	b0 = x[1];		c1 = *c;	c++;
        LDR      R7,[R6, #+24]
        LDR      R9,[R5, #+8]
        LDR      R10,[R4, #+4]
        LDR      R8,[R5, #+12]
//   87 		x[-2] = (MULSHIFT32(c0, a0) - MULSHIFT32(c1, b0)) << 1;
        MOV      R1,R7
        MOV      R0,R9
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        MOV      R11,R0
        MOV      R1,R10
        MOV      R0,R8
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        SUB      R0,R11,R0
        LSL      R0,R0,#+1
        STR      R0,[R6, #+24]
//   88 		x[1] =  (MULSHIFT32(c0, b0) + MULSHIFT32(c1, a0)) << 1;
        MOV      R1,R10
        MOV      R0,R9
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        MOV      R9,R0
        MOV      R1,R7
        MOV      R0,R8
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        ADD      R0,R0,R9
        LSL      R0,R0,#+1
        STR      R0,[R4, #+4]
//   89 
//   90 		a0 = x[-3];			c0 = *c;	c++;	b0 = x[2];		c1 = *c;	c++;
        LDR      R7,[R6, #+20]
        LDR      R9,[R5, #+16]
        LDR      R10,[R4, #+8]
        LDR      R8,[R5, #+20]
//   91 		x[-3] = (MULSHIFT32(c0, a0) - MULSHIFT32(c1, b0)) << 1;
        MOV      R1,R7
        MOV      R0,R9
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        MOV      R11,R0
        MOV      R1,R10
        MOV      R0,R8
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        SUB      R0,R11,R0
        LSL      R0,R0,#+1
        STR      R0,[R6, #+20]
//   92 		x[2] =  (MULSHIFT32(c0, b0) + MULSHIFT32(c1, a0)) << 1;
        MOV      R1,R10
        MOV      R0,R9
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        MOV      R9,R0
        MOV      R1,R7
        MOV      R0,R8
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        ADD      R0,R0,R9
        LSL      R0,R0,#+1
        STR      R0,[R4, #+8]
//   93 
//   94 		a0 = x[-4];			c0 = *c;	c++;	b0 = x[3];		c1 = *c;	c++;
        LDR      R7,[R6, #+16]
        LDR      R9,[R5, #+24]
        LDR      R10,[R4, #+12]
        LDR      R8,[R5, #+28]
//   95 		x[-4] = (MULSHIFT32(c0, a0) - MULSHIFT32(c1, b0)) << 1;
        MOV      R1,R7
        MOV      R0,R9
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        MOV      R11,R0
        MOV      R1,R10
        MOV      R0,R8
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        SUB      R0,R11,R0
        LSL      R0,R0,#+1
        STR      R0,[R6, #+16]
//   96 		x[3] =  (MULSHIFT32(c0, b0) + MULSHIFT32(c1, a0)) << 1;
        MOV      R1,R10
        MOV      R0,R9
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        MOV      R9,R0
        MOV      R1,R7
        MOV      R0,R8
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        ADD      R0,R0,R9
        LSL      R0,R0,#+1
        STR      R0,[R4, #+12]
//   97 
//   98 		a0 = x[-5];			c0 = *c;	c++;	b0 = x[4];		c1 = *c;	c++;
        LDR      R7,[R6, #+12]
        LDR      R9,[R5, #+32]
        LDR      R10,[R4, #+16]
        LDR      R8,[R5, #+36]
//   99 		x[-5] = (MULSHIFT32(c0, a0) - MULSHIFT32(c1, b0)) << 1;
        MOV      R1,R7
        MOV      R0,R9
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        MOV      R11,R0
        MOV      R1,R10
        MOV      R0,R8
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        SUB      R0,R11,R0
        LSL      R0,R0,#+1
        STR      R0,[R6, #+12]
//  100 		x[4] =  (MULSHIFT32(c0, b0) + MULSHIFT32(c1, a0)) << 1;
        MOV      R1,R10
        MOV      R0,R9
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        MOV      R9,R0
        MOV      R1,R7
        MOV      R0,R8
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        ADD      R0,R0,R9
        LSL      R0,R0,#+1
        STR      R0,[R4, #+16]
//  101 
//  102 		a0 = x[-6];			c0 = *c;	c++;	b0 = x[5];		c1 = *c;	c++;
        LDR      R7,[R6, #+8]
        LDR      R9,[R5, #+40]
        LDR      R10,[R4, #+20]
        LDR      R8,[R5, #+44]
//  103 		x[-6] = (MULSHIFT32(c0, a0) - MULSHIFT32(c1, b0)) << 1;
        MOV      R1,R7
        MOV      R0,R9
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        MOV      R11,R0
        MOV      R1,R10
        MOV      R0,R8
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        SUB      R0,R11,R0
        LSL      R0,R0,#+1
        STR      R0,[R6, #+8]
//  104 		x[5] =  (MULSHIFT32(c0, b0) + MULSHIFT32(c1, a0)) << 1;
        MOV      R1,R10
        MOV      R0,R9
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        MOV      R9,R0
        MOV      R1,R7
        MOV      R0,R8
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        ADD      R0,R0,R9
        LSL      R0,R0,#+1
        STR      R0,[R4, #+20]
//  105 
//  106 		a0 = x[-7];			c0 = *c;	c++;	b0 = x[6];		c1 = *c;	c++;
        LDR      R7,[R6, #+4]
        LDR      R9,[R5, #+48]
        LDR      R10,[R4, #+24]
        LDR      R8,[R5, #+52]
//  107 		x[-7] = (MULSHIFT32(c0, a0) - MULSHIFT32(c1, b0)) << 1;
        MOV      R1,R7
        MOV      R0,R9
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        MOV      R11,R0
        MOV      R1,R10
        MOV      R0,R8
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        SUB      R0,R11,R0
        LSL      R0,R0,#+1
        STR      R0,[R6, #+4]
//  108 		x[6] =  (MULSHIFT32(c0, b0) + MULSHIFT32(c1, a0)) << 1;
        MOV      R1,R10
        MOV      R0,R9
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        MOV      R9,R0
        MOV      R1,R7
        MOV      R0,R8
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        ADD      R0,R0,R9
        LSL      R0,R0,#+1
        STR      R0,[R4, #+24]
//  109 
//  110 		a0 = x[-8];			c0 = *c;	c++;	b0 = x[7];		c1 = *c;	c++;
        LDR      R7,[R6, #+0]
        LDR      R9,[R5, #+56]
        LDR      R10,[R4, #+28]
        LDR      R8,[R5, #+60]
//  111 		x[-8] = (MULSHIFT32(c0, a0) - MULSHIFT32(c1, b0)) << 1;
        MOV      R1,R7
        MOV      R0,R9
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        MOV      R11,R0
        MOV      R1,R10
        MOV      R0,R8
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        SUB      R0,R11,R0
        LSL      R0,R0,#+1
        STR      R0,[R6, #+0]
//  112 		x[7] =  (MULSHIFT32(c0, b0) + MULSHIFT32(c1, a0)) << 1;
        MOV      R1,R10
        MOV      R0,R9
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        MOV      R6,R0
        MOV      R1,R7
        MOV      R0,R8
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        ADD      R0,R0,R6
        LSL      R0,R0,#+1
        STR      R0,[R4, #+28]
//  113 	}
        LDR      R1,[SP, #+0]
        SUB      R1,R1,#+1
        STR      R1,[SP, #+0]
        CMP      R1,#+1
        BGE      ??AntiAlias_1
//  114 }
        POP      {R0,R1,R4-R11,PC}  ;; return
        DATA
??AntiAlias_0:
        DC32     xmp3_csa
        CFI EndBlock cfiBlock1

        RSEG CODE:CODE:NOROOT(2)
        CFI Block cfiBlock2 Using cfiCommon0
        CFI NoFunction
        THUMB
??WinPrevious??rT:
        BX       PC
        Nop      
        CFI EndBlock cfiBlock2
        REQUIRE WinPrevious
//  115 
//  116 /**************************************************************************************
//  117  * Function:    WinPrevious
//  118  *
//  119  * Description: apply specified window to second half of previous IMDCT (overlap part)
//  120  *
//  121  * Inputs:      vector of 9 coefficients (xPrev)
//  122  *
//  123  * Outputs:     18 windowed output coefficients (gain 1 integer bit)
//  124  *              window type (0, 1, 2, 3)
//  125  *
//  126  * Return:      none
//  127  *
//  128  * Notes:       produces 9 output samples from 18 input samples via symmetry
//  129  *              all blocks gain at least 1 guard bit via window (long blocks get extra
//  130  *                sign bit, short blocks can have one addition but max gain < 1.0)
//  131  **************************************************************************************/

        RSEG CODE:CODE:NOROOT(2)
        CFI Block cfiBlock3 Using cfiCommon1
        CFI Function WinPrevious
        ARM
//  132 static void WinPrevious(int *xPrev, int *xPrevWin, int btPrev)
//  133 {
WinPrevious:
        PUSH     {R4-R11,LR}
        CFI ?RET Frame(CFA, -4)
        CFI R11 Frame(CFA, -8)
        CFI R10 Frame(CFA, -12)
        CFI R9 Frame(CFA, -16)
        CFI R8 Frame(CFA, -20)
        CFI R7 Frame(CFA, -24)
        CFI R6 Frame(CFA, -28)
        CFI R5 Frame(CFA, -32)
        CFI R4 Frame(CFA, -36)
        CFI CFA R13+36
//  134 	int i, x, *xp, *xpwLo, *xpwHi, wLo, wHi;
//  135 	const int *wpLo, *wpHi;
//  136 
//  137 	xp = xPrev;
//  138 	/* mapping (see IMDCT12x3): xPrev[0-2] = sum[6-8], xPrev[3-8] = sum[12-17] */
//  139 	if (btPrev == 2) {
        LDR      R6,??DataTable4  ;; xmp3_imdctWin
        MOV      R4,R0
        MOV      R5,R1
        CMP      R2,#+2
        BNE      ??WinPrevious_0
        LDR      R0,[R6, #+312]
        LDR      R1,[R4, #+8]
//  140 		/* this could be reordered for minimum loads/stores */
//  141 		wpLo = imdctWin[btPrev];
//  142 		xPrevWin[ 0] = MULSHIFT32(wpLo[ 6], xPrev[2]) + MULSHIFT32(wpLo[0], xPrev[6]);
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        LDR      R1,[R4, #+24]
        MOV      R7,R0
        LDR      R0,[R6, #+288]
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        ADD      R0,R0,R7
        STR      R0,[R5, #+0]
        LDR      R0,[R6, #+316]
        LDR      R1,[R4, #+4]
//  143 		xPrevWin[ 1] = MULSHIFT32(wpLo[ 7], xPrev[1]) + MULSHIFT32(wpLo[1], xPrev[7]);
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        LDR      R1,[R4, #+28]
        MOV      R7,R0
        LDR      R0,[R6, #+292]
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        ADD      R0,R0,R7
        STR      R0,[R5, #+4]
        LDR      R7,[R6, #+320]
        LDR      R1,[R4, #+0]
        MOV      R0,R7
//  144 		xPrevWin[ 2] = MULSHIFT32(wpLo[ 8], xPrev[0]) + MULSHIFT32(wpLo[2], xPrev[8]);
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        LDR      R1,[R4, #+32]
        MOV      R8,R0
        LDR      R0,[R6, #+296]
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        ADD      R0,R0,R8
        STR      R0,[R5, #+8]
        LDR      R8,[R6, #+324]
        LDR      R1,[R4, #+0]
        MOV      R0,R8
//  145 		xPrevWin[ 3] = MULSHIFT32(wpLo[ 9], xPrev[0]) + MULSHIFT32(wpLo[3], xPrev[8]);
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        LDR      R1,[R4, #+32]
        MOV      R9,R0
        LDR      R0,[R6, #+300]
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        ADD      R0,R0,R9
        STR      R0,[R5, #+12]
        LDR      R9,[R6, #+328]
        LDR      R1,[R4, #+4]
        MOV      R0,R9
//  146 		xPrevWin[ 4] = MULSHIFT32(wpLo[10], xPrev[1]) + MULSHIFT32(wpLo[4], xPrev[7]);
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        LDR      R1,[R4, #+28]
        MOV      R10,R0
        LDR      R0,[R6, #+304]
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        ADD      R0,R0,R10
        STR      R0,[R5, #+16]
        LDR      R10,[R6, #+332]
        LDR      R1,[R4, #+8]
        MOV      R0,R10
//  147 		xPrevWin[ 5] = MULSHIFT32(wpLo[11], xPrev[2]) + MULSHIFT32(wpLo[5], xPrev[6]);
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        LDR      R1,[R4, #+24]
        MOV      R11,R0
        LDR      R0,[R6, #+308]
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        ADD      R0,R0,R11
        STR      R0,[R5, #+20]
//  148 		xPrevWin[ 6] = MULSHIFT32(wpLo[ 6], xPrev[5]);
        LDR      R0,[R6, #+312]
        LDR      R1,[R4, #+20]
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        STR      R0,[R5, #+24]
//  149 		xPrevWin[ 7] = MULSHIFT32(wpLo[ 7], xPrev[4]);
        LDR      R0,[R6, #+316]
        LDR      R1,[R4, #+16]
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        STR      R0,[R5, #+28]
//  150 		xPrevWin[ 8] = MULSHIFT32(wpLo[ 8], xPrev[3]);
        LDR      R1,[R4, #+12]
        MOV      R0,R7
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        STR      R0,[R5, #+32]
//  151 		xPrevWin[ 9] = MULSHIFT32(wpLo[ 9], xPrev[3]);
        LDR      R1,[R4, #+12]
        MOV      R0,R8
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        STR      R0,[R5, #+36]
//  152 		xPrevWin[10] = MULSHIFT32(wpLo[10], xPrev[4]);
        LDR      R1,[R4, #+16]
        MOV      R0,R9
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        STR      R0,[R5, #+40]
//  153 		xPrevWin[11] = MULSHIFT32(wpLo[11], xPrev[5]);
        LDR      R1,[R4, #+20]
        MOV      R0,R10
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        STR      R0,[R5, #+44]
//  154 		xPrevWin[12] = xPrevWin[13] = xPrevWin[14] = xPrevWin[15] = xPrevWin[16] = xPrevWin[17] = 0;
        MOV      R0,#+0
        STR      R0,[R5, #+68]
        STR      R0,[R5, #+64]
        STR      R0,[R5, #+60]
        STR      R0,[R5, #+56]
        STR      R0,[R5, #+52]
        STR      R0,[R5, #+48]
        POP      {R4-R11,PC}
//  155 	} else {
//  156 		/* use ARM-style pointers (*ptr++) so that ADS compiles well */
//  157 		wpLo = imdctWin[btPrev] + 18;
??WinPrevious_0:
        MOV      R0,#+144
        MLA      R1,R0,R2,R6
//  158 		wpHi = wpLo + 17;
//  159 		xpwLo = xPrevWin;
//  160 		xpwHi = xPrevWin + 17;
        ADD      R8,R5,#+68
        ADD      R6,R1,#+72
        ADD      R7,R6,#+68
//  161 		for (i = 9; i > 0; i--) {
        MOV      R9,#+9
//  162 			x = *xp++;	wLo = *wpLo++;	wHi = *wpHi--;
??WinPrevious_1:
        LDR      R10,[R4], #+4
        LDR      R0,[R6], #+4
        LDR      R11,[R7], #-4
//  163 			*xpwLo++ = MULSHIFT32(wLo, x);
        MOV      R1,R10
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        STR      R0,[R5], #+4
//  164 			*xpwHi-- = MULSHIFT32(wHi, x);
        MOV      R1,R10
        MOV      R0,R11
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        STR      R0,[R8], #-4
//  165 		}
        SUB      R9,R9,#+1
        CMP      R9,#+1
        BGE      ??WinPrevious_1
//  166 	}
//  167 }
        POP      {R4-R11,PC}      ;; return
        CFI EndBlock cfiBlock3

        RSEG CODE:CODE:NOROOT(2)
        CFI Block cfiBlock4 Using cfiCommon0
        CFI NoFunction
        THUMB
??FreqInvertRescale??rT:
        BX       PC
        Nop      
        CFI EndBlock cfiBlock4
        REQUIRE FreqInvertRescale
//  168 
//  169 /**************************************************************************************
//  170  * Function:    FreqInvertRescale
//  171  *
//  172  * Description: do frequency inversion (odd samples of odd blocks) and rescale
//  173  *                if necessary (extra guard bits added before IMDCT)
//  174  *
//  175  * Inputs:      output vector y (18 new samples, spaced NBANDS apart)
//  176  *              previous sample vector xPrev (9 samples)
//  177  *              index of current block
//  178  *              number of extra shifts added before IMDCT (usually 0)
//  179  *
//  180  * Outputs:     inverted and rescaled (as necessary) outputs
//  181  *              rescaled (as necessary) previous samples
//  182  *
//  183  * Return:      updated mOut (from new outputs y)
//  184  **************************************************************************************/

        RSEG CODE:CODE:NOROOT(2)
        CFI Block cfiBlock5 Using cfiCommon1
        CFI Function FreqInvertRescale
        ARM
//  185 static int FreqInvertRescale(int *y, int *xPrev, int blockIdx, int es)
//  186 {
FreqInvertRescale:
        PUSH     {R4-R9}
        CFI R9 Frame(CFA, -4)
        CFI R8 Frame(CFA, -8)
        CFI R7 Frame(CFA, -12)
        CFI R6 Frame(CFA, -16)
        CFI R5 Frame(CFA, -20)
        CFI R4 Frame(CFA, -24)
        CFI CFA R13+24
//  187 	int i, d, mOut;
//  188 	int y0, y1, y2, y3, y4, y5, y6, y7, y8;
//  189 
//  190 	if (es == 0) {
        CMP      R3,#+0
        BNE      ??FreqInvertRescale_0
//  191 		/* fast case - frequency invert only (no rescaling) - can fuse into overlap-add for speed, if desired */
//  192 		if (blockIdx & 0x01) {
        TST      R2,#0x1
        BEQ      ??FreqInvertRescale_1
//  193 			y += NBANDS;
//  194 			y0 = *y;	y += 2*NBANDS;
        LDR      R12,[R0, #+128]!
//  195 			y1 = *y;	y += 2*NBANDS;
        LDR      R6,[R0, #+256]
//  196 			y2 = *y;	y += 2*NBANDS;
        LDR      R7,[R0, #+512]
//  197 			y3 = *y;	y += 2*NBANDS;
        LDR      R8,[R0, #+768]!
//  198 			y4 = *y;	y += 2*NBANDS;
        LDR      R1,[R0, #+256]
//  199 			y5 = *y;	y += 2*NBANDS;
        LDR      R2,[R0, #+512]
//  200 			y6 = *y;	y += 2*NBANDS;
        LDR      R3,[R0, #+768]!
//  201 			y7 = *y;	y += 2*NBANDS;
        LDR      R4,[R0, #+256]
//  202 			y8 = *y;	y += 2*NBANDS;
        LDR      R5,[R0, #+512]!
//  203 
//  204 			y -= 18*NBANDS;
//  205 			*y = -y0;	y += 2*NBANDS;
        MVN      R9,#+255
        BIC      R9,R9,#0x700
        ADD      R0,R0,R9
        RSB      R9,R12,#+0
        STR      R9,[R0, #+0]
//  206 			*y = -y1;	y += 2*NBANDS;
        RSB      R6,R6,#+0
        STR      R6,[R0, #+256]
//  207 			*y = -y2;	y += 2*NBANDS;
        RSB      R6,R7,#+0
        STR      R6,[R0, #+512]
//  208 			*y = -y3;	y += 2*NBANDS;
        RSB      R6,R8,#+0
        STR      R6,[R0, #+768]!
//  209 			*y = -y4;	y += 2*NBANDS;
        RSB      R1,R1,#+0
        STR      R1,[R0, #+256]
//  210 			*y = -y5;	y += 2*NBANDS;
        RSB      R1,R2,#+0
        STR      R1,[R0, #+512]
//  211 			*y = -y6;	y += 2*NBANDS;
        RSB      R1,R3,#+0
        STR      R1,[R0, #+768]!
//  212 			*y = -y7;	y += 2*NBANDS;
        RSB      R1,R4,#+0
        STR      R1,[R0, #+256]!
//  213 			*y = -y8;	y += 2*NBANDS;
        RSB      R1,R5,#+0
        STR      R1,[R0, #+256]
//  214 		}
//  215 		return 0;
??FreqInvertRescale_1:
        POP      {R4-R9}
        CFI R4 SameValue
        CFI R5 SameValue
        CFI R6 SameValue
        CFI R7 SameValue
        CFI R8 SameValue
        CFI R9 SameValue
        CFI CFA R13+0
        MOV      R0,#+0
        BX       LR
        CFI R4 Frame(CFA, -24)
        CFI R5 Frame(CFA, -20)
        CFI R6 Frame(CFA, -16)
        CFI R7 Frame(CFA, -12)
        CFI R8 Frame(CFA, -8)
        CFI R9 Frame(CFA, -4)
        CFI CFA R13+24
//  216 	} else {
//  217 		/* undo pre-IMDCT scaling, clipping if necessary */
//  218 		mOut = 0;
??FreqInvertRescale_0:
        MOV      R12,#+0
//  219 		if (blockIdx & 0x01) {
        MOV      R4,R3
        RSB      R4,R4,#+31
        MOV      R5,#+1
        LSL      R5,R5,R4
        SUB      R5,R5,#+1
        TST      R2,#0x1
        MOV      R2,#+0
        BEQ      ??FreqInvertRescale_2
//  220 			/* frequency invert */
//  221 			for (i = 0; i < 18; i+=2) {
//  222 				d = *y;		CLIP_2N(d, 31 - es);	*y = d << es;	mOut |= FASTABS(*y);	y += NBANDS;
??FreqInvertRescale_3:
        LDR      R6,[R0, #+0]
//  223 				d = -*y;	CLIP_2N(d, 31 - es);	*y = d << es;	mOut |= FASTABS(*y);	y += NBANDS;
//  224 				d = *xPrev;	CLIP_2N(d, 31 - es);	*xPrev++ = d << es;
//  225 			}
        ADD      R2,R2,#+2
        ASR      R7,R6,#+31
        CMP      R7,R6, ASR R4
        EORNE    R6,R5,R7
        LSL      R6,R6,R3
        STR      R6,[R0, #+0]
        LDR      R6,[R0], #+128
        ASR      R7,R6,#+31
        EOR      R6,R7,R6
        SUB      R6,R6,R7
        ORR      R12,R6,R12
        LDR      R6,[R0, #+0]
        RSB      R6,R6,#+0
        ASR      R7,R6,#+31
        CMP      R7,R6, ASR R4
        EORNE    R6,R5,R7
        LSL      R6,R6,R3
        STR      R6,[R0, #+0]
        LDR      R6,[R0], #+128
        ASR      R7,R6,#+31
        EOR      R6,R7,R6
        SUB      R6,R6,R7
        ORR      R12,R6,R12
        LDR      R6,[R1, #+0]
        ASR      R7,R6,#+31
        CMP      R7,R6, ASR R4
        EORNE    R6,R5,R7
        LSL      R6,R6,R3
        STR      R6,[R1], #+4
        CMP      R2,#+18
        BGE      ??FreqInvertRescale_4
        B        ??FreqInvertRescale_3
//  226 		} else {
//  227 			for (i = 0; i < 18; i+=2) {
//  228 				d = *y;		CLIP_2N(d, 31 - es);	*y = d << es;	mOut |= FASTABS(*y);	y += NBANDS;
??FreqInvertRescale_2:
        LDR      R6,[R0, #+0]
//  229 				d = *y;		CLIP_2N(d, 31 - es);	*y = d << es;	mOut |= FASTABS(*y);	y += NBANDS;
//  230 				d = *xPrev;	CLIP_2N(d, 31 - es);	*xPrev++ = d << es;
//  231 			}
        ADD      R2,R2,#+2
        ASR      R7,R6,#+31
        CMP      R7,R6, ASR R4
        EORNE    R6,R5,R7
        LSL      R6,R6,R3
        STR      R6,[R0, #+0]
        LDR      R6,[R0], #+128
        ASR      R7,R6,#+31
        EOR      R6,R7,R6
        SUB      R6,R6,R7
        LDR      R7,[R0, #+0]
        ORR      R6,R6,R12
        ASR      R8,R7,#+31
        CMP      R8,R7, ASR R4
        EORNE    R7,R5,R8
        LSL      R7,R7,R3
        STR      R7,[R0, #+0]
        LDR      R7,[R0], #+128
        ASR      R8,R7,#+31
        EOR      R7,R8,R7
        SUB      R7,R7,R8
        ORR      R12,R7,R6
        LDR      R6,[R1, #+0]
        ASR      R7,R6,#+31
        CMP      R7,R6, ASR R4
        EORNE    R6,R5,R7
        LSL      R6,R6,R3
        STR      R6,[R1], #+4
        CMP      R2,#+18
        BLT      ??FreqInvertRescale_2
//  232 		}
//  233 		return mOut;
??FreqInvertRescale_4:
        POP      {R4-R9}
        CFI R4 SameValue
        CFI R5 SameValue
        CFI R6 SameValue
        CFI R7 SameValue
        CFI R8 SameValue
        CFI R9 SameValue
        CFI CFA R13+0
        MOV      R0,R12
        BX       LR               ;; return
        CFI EndBlock cfiBlock5
//  234 	}
//  235 }

        RSEG CODE:CODE:NOROOT(2)
        CFI Block cfiBlock6 Using cfiCommon0
        CFI NoFunction
        THUMB
??idct9??rT:
        BX       PC
        Nop      
        CFI EndBlock cfiBlock6
        REQUIRE idct9
//  236 
//  237 /* format = Q31
//  238  * #define M_PI 3.14159265358979323846
//  239  * double u = 2.0 * M_PI / 9.0;
//  240  * float c0 = sqrt(3.0) / 2.0;
//  241  * float c1 = cos(u);
//  242  * float c2 = cos(2*u);
//  243  * float c3 = sin(u);
//  244  * float c4 = sin(2*u);
//  245  */
//  246 static const int c9_0 = 0x6ed9eba1;
//  247 static const int c9_1 = 0x620dbe8b;
//  248 static const int c9_2 = 0x163a1a7e;
//  249 static const int c9_3 = 0x5246dd49;
//  250 static const int c9_4 = 0x7e0e2e32;
//  251 
//  252 /* format = Q31
//  253  * cos(((0:8) + 0.5) * (pi/18))
//  254  */
//  255 static const int c18[9] = {
//  256 	0x7f834ed0, 0x7ba3751d, 0x7401e4c1, 0x68d9f964, 0x5a82799a, 0x496af3e2, 0x36185aee, 0x2120fb83, 0x0b27eb5c,
//  257 };
//  258 
//  259 /* require at least 3 guard bits in x[] to ensure no overflow */

        RSEG CODE:CODE:NOROOT(2)
        CFI Block cfiBlock7 Using cfiCommon1
        CFI Function idct9
        ARM
//  260 static  void idct9(int *x)
//  261 {
idct9:
        PUSH     {R4-R11,LR}
        CFI ?RET Frame(CFA, -4)
        CFI R11 Frame(CFA, -8)
        CFI R10 Frame(CFA, -12)
        CFI R9 Frame(CFA, -16)
        CFI R8 Frame(CFA, -20)
        CFI R7 Frame(CFA, -24)
        CFI R6 Frame(CFA, -28)
        CFI R5 Frame(CFA, -32)
        CFI R4 Frame(CFA, -36)
        CFI CFA R13+36
        SUB      SP,SP,#+28
        CFI CFA R13+64
        MOV      R4,R0
//  262 	int a1, a2, a3, a4, a5, a6, a7, a8, a9;
//  263 	int a10, a11, a12, a13, a14, a15, a16, a17, a18;
//  264 	int a19, a20, a21, a22, a23, a24, a25, a26, a27;
//  265 	int m1, m3, m5, m6, m7, m8, m9, m10, m11, m12;
//  266 	int x0, x1, x2, x3, x4, x5, x6, x7, x8;
//  267 
//  268 	x0 = x[0]; x1 = x[1]; x2 = x[2]; x3 = x[3]; x4 = x[4];
        LDR      R5,[R4, #+4]
//  269 	x5 = x[5]; x6 = x[6]; x7 = x[7]; x8 = x[8];
        LDR      R8,[R4, #+20]
//  270 
//  271 	a1 = x0 - x6;
        LDR      R6,[R4, #+0]
        LDR      R7,[R4, #+24]
        LDR      R0,[R4, #+8]
        LDR      R1,[R4, #+16]
        LDR      R10,[R4, #+28]
        LDR      R2,[R4, #+32]
        SUB      R6,R6,R7
        STR      R6,[SP, #+8]
//  272 	a2 = x1 - x5;
//  273 	a3 = x1 + x5;
        ADD      R6,R8,R5
        STR      R6,[SP, #+0]
//  274 	a4 = x2 - x4;
//  275 	a5 = x2 + x4;
//  276 	a6 = x2 + x8;
//  277 	a7 = x1 + x7;
//  278 
//  279 	a8 = a6 - a5;		/* ie x[8] - x[4] */
//  280 	a9 = a3 - a7;		/* ie x[5] - x[7] */
        LDR      R11,[SP, #+0]
        ADD      R9,R10,R5
        SUB      R11,R11,R9
        STR      R11,[SP, #+4]
//  281 	a10 = a2 - x7;		/* ie x[1] - x[5] - x[7] */
//  282 	a11 = a4 - x8;		/* ie x[2] - x[4] - x[8] */
//  283 
//  284 	/* do the << 1 as constant shifts where mX is actually used (free, no stall or extra inst.) */
//  285 	m1 =  MULSHIFT32(c9_0, x3);
        LDR      R11,??DataTable3  ;; 0x6ed9eba1
        ADD      R7,R1,R0
        ADD      R6,R2,R0
        SUB      R0,R0,R1
        SUB      R0,R0,R2
        STR      R0,[SP, #+12]
        LDR      R1,[R4, #+12]
        MOV      R0,R11
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        STR      R0,[SP, #+16]
//  286 	m3 =  MULSHIFT32(c9_0, a10);
        SUB      R0,R5,R8
//  287 	m5 =  MULSHIFT32(c9_1, a5);
        LDR      R8,??idct9_0     ;; 0x620dbe8b
        SUB      R1,R0,R10
//  288 	m6 =  MULSHIFT32(c9_2, a6);
        LDR      R10,??idct9_0+0x4  ;; 0x163a1a7e
        MOV      R0,R11
//  289 	m7 =  MULSHIFT32(c9_1, a8);
//  290 	m8 =  MULSHIFT32(c9_2, a5);
//  291 	m9 =  MULSHIFT32(c9_3, a9);
//  292 	m10 = MULSHIFT32(c9_4, a7);
        LDR      R11,??idct9_0+0x8  ;; 0x7e0e2e32
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        STR      R0,[SP, #+24]
        MOV      R1,R7
        MOV      R0,R8
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        STR      R0,[SP, #+20]
        MOV      R1,R6
        MOV      R0,R10
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        MOV      R5,R0
        SUB      R1,R6,R7
        MOV      R0,R8
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        MOV      R6,R0
        MOV      R0,R10
        LDR      R10,??idct9_0+0xC  ;; 0x5246dd49
        MOV      R1,R7
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        LDR      R1,[SP, #+4]
        MOV      R7,R0
        MOV      R0,R10
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        MOV      R8,R0
        MOV      R1,R9
        MOV      R0,R11
        _BLF     MULSHIFT32,??MULSHIFT32??rA
//  293 	m11 = MULSHIFT32(c9_3, a3);
        LDR      R1,[SP, #+0]
        MOV      R9,R0
        MOV      R0,R10
        _BLF     MULSHIFT32,??MULSHIFT32??rA
//  294 	m12 = MULSHIFT32(c9_4, a9);
        LDR      R1,[SP, #+4]
        MOV      R10,R0
        MOV      R0,R11
        _BLF     MULSHIFT32,??MULSHIFT32??rA
//  295 
//  296 	a12 = x[0] +  (x[6] >> 1);
        LDR      R1,[R4, #+0]
        LDR      R2,[R4, #+24]
//  297 	a13 = a12  +  (  m1 << 1);
//  298 	a14 = a12  -  (  m1 << 1);
//  299 	a15 = a1   +  ( a11 >> 1);
        LDR      R11,[SP, #+12]
        ADD      R2,R1,R2, ASR #+1
        LDR      R1,[SP, #+16]
//  300 	a16 = ( m5 << 1) + (m6 << 1);
//  301 	a17 = ( m7 << 1) - (m8 << 1);
//  302 	a18 = a16 + a17;
//  303 	a19 = ( m9 << 1) + (m10 << 1);
        ADD      R8,R9,R8
        LSL      R3,R1,#+1
        ADD      R1,R3,R2
        SUB      R2,R2,R3
        LDR      R3,[SP, #+8]
        LSL      R8,R8,#+1
        ADD      R3,R3,R11, ASR #+1
        LDR      R11,[SP, #+20]
//  304 	a20 = (m11 << 1) - (m12 << 1);
        SUB      R0,R10,R0
        ADD      R5,R5,R11
        LSL      R5,R5,#+1
//  305 
//  306 	a21 = a20 - a19;
//  307 	a22 = a13 + a16;
//  308 	a23 = a14 + a16;
//  309 	a24 = a14 + a17;
//  310 	a25 = a13 + a17;
//  311 	a26 = a14 - a18;
//  312 	a27 = a13 - a18;
//  313 
//  314 	x0 = a22 + a19;			x[0] = x0;
        ADD      R10,R5,R1
        ADD      R10,R8,R10
        STR      R10,[R4, #+0]
//  315 	x1 = a15 + (m3 << 1);	x[1] = x1;
        LDR      R10,[SP, #+24]
        SUB      R6,R6,R7
        LSL      R6,R6,#+1
        ADD      R7,R6,R5
        LSL      R0,R0,#+1
        SUB      R9,R0,R8
        LSL      R10,R10,#+1
        ADD      R11,R10,R3
        STR      R11,[R4, #+4]
//  316 	x2 = a24 + a20;			x[2] = x2;
        ADD      R11,R6,R2
        ADD      R11,R0,R11
        STR      R11,[R4, #+8]
//  317 	x3 = a26 - a21;			x[3] = x3;
        SUB      R11,R2,R7
        SUB      R11,R11,R9
        STR      R11,[R4, #+12]
//  318 	x4 = a1 - a11;			x[4] = x4;
        LDR      R11,[SP, #+8]
        LDR      R12,[SP, #+12]
//  319 	x5 = a27 + a21;			x[5] = x5;
        SUB      R7,R1,R7
        SUB      R11,R11,R12
        STR      R11,[R4, #+16]
        ADD      R7,R9,R7
        STR      R7,[R4, #+20]
//  320 	x6 = a25 - a20;			x[6] = x6;
        ADD      R1,R6,R1
        SUB      R0,R1,R0
        STR      R0,[R4, #+24]
//  321 	x7 = a15 - (m3 << 1);	x[7] = x7;
        SUB      R0,R3,R10
        STR      R0,[R4, #+28]
//  322 	x8 = a23 - a19;			x[8] = x8;
        ADD      R0,R5,R2
        SUB      R0,R0,R8
        STR      R0,[R4, #+32]
//  323 }
        ADD      SP,SP,#+28
        CFI CFA R13+36
        POP      {R4-R11,PC}      ;; return
        DATA
??idct9_0:
        DC32     0x620dbe8b
        DC32     0x163a1a7e
        DC32     0x7e0e2e32
        DC32     0x5246dd49
        CFI EndBlock cfiBlock7

        RSEG CODE:CODE:NOROOT(2)
        CFI Block cfiBlock8 Using cfiCommon0
        CFI NoFunction
        THUMB
??IMDCT36??rT:
        BX       PC
        Nop      
        CFI EndBlock cfiBlock8
        REQUIRE IMDCT36

        RSEG DATA_C:CONST:SORT:NOROOT(2)
c18:
        DATA
        DC32 2139311824, 2074309917, 1946281153, 1759115620, 1518500250
        DC32 1231746018, 907565806, 555809667, 187165532
        DC32 1118490251, -1024907484, 1194400808, -916495974, 1250332651
        DC32 -796549748, 1284586321, -668713312, 1296121036, -536870912
        DC32 1284586321, -405028511, 1250332651, -277192075, 1194400808
        DC32 -157245849, 1118490251, -48834339
//  324 
//  325 /* let c(j) = cos(M_PI/36 * ((j)+0.5)), s(j) = sin(M_PI/36 * ((j)+0.5))
//  326  * then fastWin[2*j+0] = c(j)*(s(j) + c(j)), j = [0, 8]
//  327  *      fastWin[2*j+1] = c(j)*(s(j) - c(j))
//  328  * format = Q30
//  329  */
//  330 static const int fastWin36[18] = {
//  331 	0x42aace8b, 0xc2e92724, 0x47311c28, 0xc95f619a, 0x4a868feb, 0xd0859d8c,
//  332 	0x4c913b51, 0xd8243ea0, 0x4d413ccc, 0xe0000000, 0x4c913b51, 0xe7dbc161,
//  333 	0x4a868feb, 0xef7a6275, 0x47311c28, 0xf6a09e67, 0x42aace8b, 0xfd16d8dd,
//  334 };
//  335 
//  336 /**************************************************************************************
//  337  * Function:    IMDCT36
//  338  *
//  339  * Description: 36-point modified DCT, with windowing and overlap-add (50% overlap)
//  340  *
//  341  * Inputs:      vector of 18 coefficients (N/2 inputs produces N outputs, by symmetry)
//  342  *              overlap part of last IMDCT (9 samples - see output comments)
//  343  *              window type (0,1,2,3) of current and previous block
//  344  *              current block index (for deciding whether to do frequency inversion)
//  345  *              number of guard bits in input vector
//  346  *
//  347  * Outputs:     18 output samples, after windowing and overlap-add with last frame
//  348  *              second half of (unwindowed) 36-point IMDCT - save for next time
//  349  *                only save 9 xPrev samples, using symmetry (see WinPrevious())
//  350  *
//  351  * Notes:       this is Ken's hyper-fast algorithm, including symmetric sin window
//  352  *                optimization, if applicable
//  353  *              total number of multiplies, general case:
//  354  *                2*10 (idct9) + 9 (last stage imdct) + 36 (for windowing) = 65
//  355  *              total number of multiplies, btCurr == 0 && btPrev == 0:
//  356  *                2*10 (idct9) + 9 (last stage imdct) + 18 (for windowing) = 47
//  357  *
//  358  *              blockType == 0 is by far the most common case, so it should be
//  359  *                possible to use the fast path most of the time
//  360  *              this is the fastest known algorithm for performing
//  361  *                long IMDCT + windowing + overlap-add in MP3
//  362  *
//  363  * Return:      mOut (OR of abs(y) for all y calculated here)
//  364  *
//  365  * TODO:        optimize for ARM (reorder window coefs, ARM-style pointers in C,
//  366  *                inline asm may or may not be helpful)
//  367  **************************************************************************************/

        RSEG CODE:CODE:NOROOT(2)
        CFI Block cfiBlock9 Using cfiCommon1
        CFI Function IMDCT36
        ARM
//  368 static int IMDCT36(int *xCurr, int *xPrev, int *y, int btCurr, int btPrev, int blockIdx, int gb)
//  369 {
IMDCT36:
        PUSH     {R2,R4-R11,LR}
        CFI ?RET Frame(CFA, -4)
        CFI R11 Frame(CFA, -8)
        CFI R10 Frame(CFA, -12)
        CFI R9 Frame(CFA, -16)
        CFI R8 Frame(CFA, -20)
        CFI R7 Frame(CFA, -24)
        CFI R6 Frame(CFA, -28)
        CFI R5 Frame(CFA, -32)
        CFI R4 Frame(CFA, -36)
        CFI CFA R13+40
        SUB      SP,SP,#+156
        CFI CFA R13+196
        LDR      R2,[SP, #+204]
        LDR      R9,[SP, #+196]
        MOV      R4,R1
        MOV      R8,R3
//  370 	int i, es, xBuf[18], xPrevWin[18];
//  371 	int acc1, acc2, s, d, t, mOut;
//  372 	int xo, xe, c, *xp, yLo, yHi;
//  373 	const int *cp, *wp;
//  374 
//  375 	acc1 = acc2 = 0;
        MOV      R1,#+0
        MOV      R3,#+0
//  376 	xCurr += 17;
        ADD      R0,R0,#+68
//  377 
//  378 	/* 7 gb is always adequate for antialias + accumulator loop + idct9 */
//  379 	if (gb < 7) {
        CMP      R2,#+7
        BGE      ??IMDCT36_0
//  380 		/* rarely triggered - 5% to 10% of the time on normal clips (with Q25 input) */
//  381 		es = 7 - gb;
        RSB      R5,R2,#+7
//  382 		for (i = 8; i >= 0; i--) {
        MOV      R2,#+8
//  383 			acc1 = ((*xCurr--) >> es) - acc1;
??IMDCT36_1:
        LDR      R6,[R0], #-4
        RSB      R3,R3,R6, ASR R5
//  384 			acc2 = acc1 - acc2;
//  385 			acc1 = ((*xCurr--) >> es) - acc1;
        LDR      R6,[R0], #-4
        SUB      R1,R3,R1
        RSB      R3,R3,R6, ASR R5
//  386 			xBuf[i+9] = acc2;	/* odd */
        ADD      R6,SP,#+12
        ADD      R6,R6,R2, LSL #+2
        STR      R1,[R6, #+36]
//  387 			xBuf[i+0] = acc1;	/* even */
        STR      R3,[R6, #+0]
//  388 			xPrev[i] >>= es;
        LDR      R6,[R4, +R2, LSL #+2]
        ASR      R6,R6,R5
        STR      R6,[R4, +R2, LSL #+2]
//  389 		}
        SUBS     R2,R2,#+1
        BMI      ??IMDCT36_2
        B        ??IMDCT36_1
//  390 	} else {
//  391 		es = 0;
??IMDCT36_0:
        MOV      R5,#+0
//  392 		/* max gain = 18, assume adequate guard bits */
//  393 		for (i = 8; i >= 0; i--) {
        MOV      R2,#+8
//  394 			acc1 = (*xCurr--) - acc1;
??IMDCT36_3:
        LDR      R6,[R0], #-4
        SUB      R3,R6,R3
//  395 			acc2 = acc1 - acc2;
//  396 			acc1 = (*xCurr--) - acc1;
        LDR      R6,[R0], #-4
        SUB      R1,R3,R1
        SUB      R3,R6,R3
//  397 			xBuf[i+9] = acc2;	/* odd */
        ADD      R6,SP,#+12
        ADD      R6,R6,R2, LSL #+2
        STR      R1,[R6, #+36]
//  398 			xBuf[i+0] = acc1;	/* even */
        STR      R3,[R6, #+0]
//  399 		}
        SUBS     R2,R2,#+1
        BPL      ??IMDCT36_3
//  400 	}
//  401 	/* xEven[0] and xOdd[0] scaled by 0.5 */
//  402 	xBuf[9] >>= 1;
??IMDCT36_2:
        LDR      R1,[SP, #+48]
//  403 	xBuf[0] >>= 1;
//  404 
//  405 	/* do 9-point IDCT on even and odd */
//  406 	idct9(xBuf+0);	/* even */
        ADD      R0,SP,#+12
        ASR      R1,R1,#+1
        STR      R1,[SP, #+48]
        LDR      R1,[SP, #+12]
//  407 	idct9(xBuf+9);	/* odd */
//  408 
//  409 	xp = xBuf + 8;
//  410 	cp = c18 + 8;
//  411 	mOut = 0;
        MOV      R7,#+0
        ASR      R1,R1,#+1
        STR      R1,[SP, #+12]
        BL       idct9
        ADD      R0,SP,#+48
        BL       idct9
        LDR      R0,??IMDCT36_4   ;; c18
        ADD      R6,SP,#+44
        ADD      R2,R0,#+32
        STR      R2,[SP, #+8]
//  412 	if (btPrev == 0 && btCurr == 0) {
        CMP      R9,#+0
        CMPEQ    R8,#+0
        BNE      ??IMDCT36_5
//  413 		/* fast path - use symmetry of sin window to reduce windowing multiplies to 18 (N/2) */
//  414 		wp = fastWin36;
        ADD      R8,R0,#+36
//  415 		for (i = 0; i < 9; i++) {
//  416 			/* do ARM-style pointer arithmetic (i still needed for y[] indexing - compiler spills if 2 y pointers) */
//  417 			c = *cp--;	xo = *(xp + 9);		xe = *xp--;
??IMDCT36_6:
        LDR      R2,[SP, #+8]
        LDR      R0,[R2], #-4
        STR      R2,[SP, #+8]
        LDR      R1,[R6, #+36]
        LDR      R10,[R6], #-4
//  418 			/* gain 2 int bits here */
//  419 			xo = MULSHIFT32(c, xo);			/* 2*c18*xOdd (mul by 2 implicit in scaling)  */
        _BLF     MULSHIFT32,??MULSHIFT32??rA
//  420 			xe >>= 2;
//  421 
//  422 			s = -(*xPrev);		/* sum from last block (always at least 2 guard bits) */
        LDR      R3,[R4, #+0]
        ASR      R1,R10,#+2
        RSB      R3,R3,#+0
        STR      R3,[SP, #+0]
//  423 			d = -(xe - xo);		/* gain 2 int bits, don't shift xo (effective << 1 to eat sign bit, << 1 for mul by 2) */
        SUB      R10,R0,R1
//  424 			(*xPrev++) = xe + xo;			/* symmetry - xPrev[i] = xPrev[17-i] for long blocks */
        ADD      R0,R0,R1
        STR      R0,[R4], #+4
//  425 			t = s - d;
        LDR      R1,[SP, #+0]
        SUB      R1,R1,R10
        STR      R1,[SP, #+4]
//  426 
//  427 			yLo = (d + (MULSHIFT32(t, *wp++) << 2));
        LDR      R0,[SP, #+4]
        LDR      R1,[R8], #+4
        _BLF     MULSHIFT32,??MULSHIFT32??rA
//  428 			yHi = (s + (MULSHIFT32(t, *wp++) << 2));
        LDR      R1,[R8], #+4
        ADD      R11,R10,R0, LSL #+2
        LDR      R10,[SP, #+0]
        LDR      R0,[SP, #+4]
        _BLF     MULSHIFT32,??MULSHIFT32??rA
//  429 			y[(i)*NBANDS]    = 	yLo;
        LDR      R1,[SP, #+156]
        ADD      R0,R10,R0, LSL #+2
        STR      R11,[R1, +R9, LSL #+7]
//  430 			y[(17-i)*NBANDS] =  yHi;
        LDR      R2,[SP, #+156]
        MOV      R1,R9
        RSB      R1,R1,#+0
        ADD      R1,R2,R1, LSL #+7
        STR      R0,[R1, #+2176]
//  431 			mOut |= FASTABS(yLo);
        ASR      R1,R11,#+31
//  432 			mOut |= FASTABS(yHi);
        ASR      R2,R0,#+31
        EOR      R3,R1,R11
        SUB      R1,R3,R1
        EOR      R0,R2,R0
        SUB      R0,R0,R2
        ORR      R0,R0,R1
        ORR      R7,R0,R7
//  433 		}
        ADD      R9,R9,#+1
        CMP      R9,#+9
        BGE      ??IMDCT36_7
        B        ??IMDCT36_6
//  434 	} else {
//  435 		/* slower method - either prev or curr is using window type != 0 so do full 36-point window
//  436 		 * output xPrevWin has at least 3 guard bits (xPrev has 2, gain 1 in WinPrevious)
//  437 		 */
//  438 		WinPrevious(xPrev, xPrevWin, btPrev);
??IMDCT36_5:
        MOV      R2,R9
        ADD      R1,SP,#+84
        MOV      R0,R4
        BL       WinPrevious
//  439 
//  440 		wp = imdctWin[btCurr];
        LDR      R1,??DataTable4  ;; xmp3_imdctWin
        MOV      R0,#+144
        MLA      R8,R0,R8,R1
//  441 		for (i = 0; i < 9; i++) {
        MOV      R9,#+0
//  442 			c = *cp--;	xo = *(xp + 9);		xe = *xp--;
??IMDCT36_8:
        LDR      R2,[SP, #+8]
        LDR      R0,[R2], #-4
        STR      R2,[SP, #+8]
        LDR      R1,[R6, #+36]
        LDR      R10,[R6], #-4
//  443 			/* gain 2 int bits here */
//  444 			xo = MULSHIFT32(c, xo);			/* 2*c18*xOdd (mul by 2 implicit in scaling)  */
        _BLF     MULSHIFT32,??MULSHIFT32??rA
//  445 			xe >>= 2;
        ASR      R1,R10,#+2
//  446 
//  447 			d = xe - xo;
        SUB      R10,R1,R0
//  448 			(*xPrev++) = xe + xo;	/* symmetry - xPrev[i] = xPrev[17-i] for long blocks */
        ADD      R0,R0,R1
        STR      R0,[R4], #+4
//  449 
//  450 			yLo = (xPrevWin[i]    + MULSHIFT32(d, wp[i])) << 2;
        LDR      R1,[R8, +R9, LSL #+2]
        MOV      R0,R10
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        ADD      R1,SP,#+84
        LDR      R1,[R1, +R9, LSL #+2]
        ADD      R0,R0,R1
        LSL      R11,R0,#+2
        MOV      R0,R9
        RSB      R0,R0,#+0
        ADD      R0,R8,R0, LSL #+2
        LDR      R1,[R0, #+68]
        MOV      R0,R10
//  451 			yHi = (xPrevWin[17-i] + MULSHIFT32(d, wp[17-i])) << 2;
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        MOV      R1,R9
        RSB      R1,R1,#+0
        ADD      R2,SP,#+84
        ADD      R1,R2,R1, LSL #+2
        LDR      R1,[R1, #+68]
        ADD      R0,R0,R1
//  452 			y[(i)*NBANDS]    = yLo;
        LDR      R1,[SP, #+156]
        LSL      R0,R0,#+2
        STR      R11,[R1, +R9, LSL #+7]
//  453 			y[(17-i)*NBANDS] = yHi;
        LDR      R2,[SP, #+156]
        MOV      R1,R9
        RSB      R1,R1,#+0
        ADD      R1,R2,R1, LSL #+7
        STR      R0,[R1, #+2176]
//  454 			mOut |= FASTABS(yLo);
        ASR      R1,R11,#+31
//  455 			mOut |= FASTABS(yHi);
        ASR      R2,R0,#+31
        EOR      R3,R1,R11
        SUB      R1,R3,R1
        EOR      R0,R2,R0
        SUB      R0,R0,R2
        ORR      R0,R0,R1
        ORR      R7,R0,R7
//  456 		}
        ADD      R9,R9,#+1
        CMP      R9,#+9
        BLT      ??IMDCT36_8
//  457 	}
//  458 
//  459 	xPrev -= 9;
//  460 	mOut |= FreqInvertRescale(y, xPrev, blockIdx, es);
??IMDCT36_7:
        LDR      R0,[SP, #+156]
        LDR      R2,[SP, #+200]
        MOV      R3,R5
        SUB      R1,R4,#+36
        BL       FreqInvertRescale
        ORR      R0,R0,R7
//  461 
//  462 	return mOut;
        ADD      SP,SP,#+160
        CFI CFA R13+36
        POP      {R4-R11,PC}      ;; return
        DATA
??IMDCT36_4:
        DC32     c18
        CFI EndBlock cfiBlock9
//  463 }

        RSEG CODE:CODE:NOROOT(2)
        CFI Block cfiBlock10 Using cfiCommon0
        CFI NoFunction
        THUMB
??imdct12??rT:
        BX       PC
        Nop      
        CFI EndBlock cfiBlock10
        REQUIRE imdct12
//  464 
//  465 static const int c3_0 = 0x6ed9eba1;	/* format = Q31, cos(pi/6) */
//  466 static const int c6[3] = { 0x7ba3751d, 0x5a82799a, 0x2120fb83 };	/* format = Q31, cos(((0:2) + 0.5) * (pi/6)) */
//  467 
//  468 /* 12-point inverse DCT, used in IMDCT12x3()
//  469  * 4 input guard bits will ensure no overflow
//  470  */

        RSEG CODE:CODE:NOROOT(2)
        CFI Block cfiBlock11 Using cfiCommon1
        CFI Function imdct12
        ARM
//  471 static  void imdct12 (int *x, int *out)
//  472 {
imdct12:
        PUSH     {R4-R11,LR}
        CFI ?RET Frame(CFA, -4)
        CFI R11 Frame(CFA, -8)
        CFI R10 Frame(CFA, -12)
        CFI R9 Frame(CFA, -16)
        CFI R8 Frame(CFA, -20)
        CFI R7 Frame(CFA, -24)
        CFI R6 Frame(CFA, -28)
        CFI R5 Frame(CFA, -32)
        CFI R4 Frame(CFA, -36)
        CFI CFA R13+36
//  473 	int a0, a1, a2;
//  474 	int x0, x1, x2, x3, x4, x5;
//  475 
//  476 	x0 = *x;	x+=3;	x1 = *x;	x+=3;
        LDR      R2,[R0], #+12
        LDR      R3,[R0], #+12
//  477 	x2 = *x;	x+=3;	x3 = *x;	x+=3;
//  478 	x4 = *x;	x+=3;	x5 = *x;	x+=3;
//  479 
//  480 	x4 -= x5;
//  481 	x3 -= x4;
//  482 	x2 -= x3;
//  483 	x3 -= x5;
//  484 	x1 -= x2;
//  485 	x0 -= x1;
//  486 	x1 -= x3;
//  487 
//  488 	x0 >>= 1;
//  489 	x1 >>= 1;
//  490 
//  491 	a0 = MULSHIFT32(c3_0, x2) << 1;
        LDR      R9,??DataTable3  ;; 0x6ed9eba1
        MOV      R5,R1
        LDR      R1,[R0], #+12
        LDR      R7,[R0], #+12
        LDR      R6,[R0, #+12]
        LDR      R0,[R0, #+0]
        SUB      R4,R0,R6
        SUB      R0,R7,R4
        SUB      R1,R1,R0
        SUB      R7,R0,R6
        SUB      R0,R3,R1
        SUB      R2,R2,R0
        ASR      R10,R2,#+1
        SUB      R0,R0,R7
        ASR      R8,R0,#+1
        MOV      R0,R9
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        LSL      R0,R0,#+1
//  492 	a1 = x0 + (x4 >> 1);
        ADD      R1,R10,R4, ASR #+1
//  493 	a2 = x0 - x4;
        SUB      R4,R10,R4
//  494 	x0 = a1 + a0;
        ADD      R10,R0,R1
//  495 	x2 = a2;
//  496 	x4 = a1 - a0;
        SUB      R11,R1,R0
//  497 
//  498 	a0 = MULSHIFT32(c3_0, x3) << 1;
        MOV      R1,R7
        MOV      R0,R9
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        LSL      R7,R0,#+1
//  499 	a1 = x1 + (x5 >> 1);
//  500 	a2 = x1 - x5;
//  501 
//  502 	/* cos window odd samples, mul by 2, eat sign bit */
//  503 	x1 = MULSHIFT32(c6[0], a1 + a0) << 2;
        LDR      R0,??imdct12_0   ;; 0x7ba3751d
        ADD      R9,R8,R6, ASR #+1
        SUB      R8,R8,R6
        ADD      R1,R7,R9
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        LSL      R6,R0,#+2
//  504 	x3 = MULSHIFT32(c6[1], a2) << 2;
        LDR      R0,??imdct12_0+0x4  ;; 0x5a82799a
        MOV      R1,R8
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        LSL      R8,R0,#+2
//  505 	x5 = MULSHIFT32(c6[2], a1 - a0) << 2;
        LDR      R0,??imdct12_0+0x8  ;; 0x2120fb83
        SUB      R1,R9,R7
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        LSL      R0,R0,#+2
//  506 
//  507 	*out = x0 + x1;	out++;
        ADD      R1,R6,R10
        STR      R1,[R5], #+4
//  508 	*out = x2 + x3;	out++;
        ADD      R1,R8,R4
        STR      R1,[R5], #+4
//  509 	*out = x4 + x5;	out++;
        ADD      R1,R0,R11
        STR      R1,[R5], #+4
//  510 	*out = x4 - x5;	out++;
        SUB      R0,R11,R0
        STR      R0,[R5], #+4
//  511 	*out = x2 - x3;	out++;
        SUB      R0,R4,R8
        STR      R0,[R5], #+4
//  512 	*out = x0 - x1;
        SUB      R0,R10,R6
        STR      R0,[R5, #+0]
//  513 }
        POP      {R4-R11,PC}      ;; return
        DATA
??imdct12_0:
        DC32     0x7ba3751d
        DC32     0x5a82799a
        DC32     0x2120fb83
        CFI EndBlock cfiBlock11

        RSEG CODE:CODE:NOROOT(2)
        DATA
??DataTable3:
        DC32     0x6ed9eba1

        RSEG CODE:CODE:NOROOT(2)
        CFI Block cfiBlock12 Using cfiCommon0
        CFI NoFunction
        THUMB
??IMDCT12x3??rT:
        BX       PC
        Nop      
        CFI EndBlock cfiBlock12
        REQUIRE IMDCT12x3
//  514 
//  515 /**************************************************************************************
//  516  * Function:    IMDCT12x3
//  517  *
//  518  * Description: three 12-point modified DCT's for short blocks, with windowing,
//  519  *                short block concatenation, and overlap-add
//  520  *
//  521  * Inputs:      3 interleaved vectors of 6 samples each
//  522  *                (block0[0], block1[0], block2[0], block0[1], block1[1]....)
//  523  *              overlap part of last IMDCT (9 samples - see output comments)
//  524  *              window type (0,1,2,3) of previous block
//  525  *              current block index (for deciding whether to do frequency inversion)
//  526  *              number of guard bits in input vector
//  527  *
//  528  * Outputs:     updated sample vector x, net gain of 1 integer bit
//  529  *              second half of (unwindowed) IMDCT's - save for next time
//  530  *                only save 9 xPrev samples, using symmetry (see WinPrevious())
//  531  *
//  532  * Return:      mOut (OR of abs(y) for all y calculated here)
//  533  *
//  534  * TODO:        optimize for ARM
//  535  **************************************************************************************/

        RSEG CODE:CODE:NOROOT(2)
        CFI Block cfiBlock13 Using cfiCommon1
        CFI Function IMDCT12x3
        ARM
//  536 static int IMDCT12x3(int *xCurr, int *xPrev, int *y, int btPrev, int blockIdx, int gb)
//  537 {
IMDCT12x3:
        PUSH     {R2,R4-R11,LR}
        CFI ?RET Frame(CFA, -4)
        CFI R11 Frame(CFA, -8)
        CFI R10 Frame(CFA, -12)
        CFI R9 Frame(CFA, -16)
        CFI R8 Frame(CFA, -20)
        CFI R7 Frame(CFA, -24)
        CFI R6 Frame(CFA, -28)
        CFI R5 Frame(CFA, -32)
        CFI R4 Frame(CFA, -36)
        CFI CFA R13+40
        SUB      SP,SP,#+188
        CFI CFA R13+228
        MOV      R6,R0
        LDR      R0,[SP, #+232]
        MOV      R5,R1
        MOV      R7,R3
//  538 	int i, es, mOut, yLo, xBuf[18], xPrevWin[18];	/* need temp buffer for reordering short blocks */
//  539 	const int *wp;
//  540 
//  541 	es = 0;
        MOV      R4,#+0
//  542 	/* 7 gb is always adequate for accumulator loop + idct12 + window + overlap */
//  543 	if (gb < 7) {
        CMP      R0,#+7
        BGE      ??IMDCT12x3_0
//  544 		es = 7 - gb;
        RSB      R4,R0,#+7
//  545 		for (i = 0; i < 18; i+=2) {
        MOV      R0,#+0
//  546 			xCurr[i+0] >>= es;
??IMDCT12x3_1:
        ADD      R1,R6,R0, LSL #+2
        LDR      R2,[R1, #+0]
//  547 			xCurr[i+1] >>= es;
//  548 			*xPrev++ >>= es;
//  549 		}
        ADD      R0,R0,#+2
        ASR      R2,R2,R4
        STR      R2,[R1, #+0]
        LDR      R2,[R1, #+4]
        CMP      R0,#+18
        ASR      R2,R2,R4
        STR      R2,[R1, #+4]
        MOV      R1,R5
        LDR      R2,[R1, #+0]
        ADD      R5,R1,#+4
        ASR      R2,R2,R4
        STR      R2,[R1, #+0]
        BLT      ??IMDCT12x3_1
//  550 		xPrev -= 9;
        SUB      R5,R5,#+36
//  551 	}
//  552 
//  553 	/* requires 4 input guard bits for each imdct12 */
//  554 	imdct12(xCurr + 0, xBuf + 0);
??IMDCT12x3_0:
        ADD      R1,SP,#+44
        MOV      R0,R6
        BL       imdct12
//  555 	imdct12(xCurr + 1, xBuf + 6);
        ADD      R1,SP,#+68
        ADD      R0,R6,#+4
        BL       imdct12
//  556 	imdct12(xCurr + 2, xBuf + 12);
        ADD      R1,SP,#+92
        ADD      R0,R6,#+8
        BL       imdct12
//  557 
//  558 	/* window previous from last time */
//  559 	WinPrevious(xPrev, xPrevWin, btPrev);
        MOV      R2,R7
        ADD      R1,SP,#+116
        MOV      R0,R5
        BL       WinPrevious
//  560 
//  561 	/* could unroll this for speed, minimum loads (short blocks usually rare, so doesn't make much overall difference)
//  562 	 * xPrevWin[i] << 2 still has 1 gb always, max gain of windowed xBuf stuff also < 1.0 and gain the sign bit
//  563 	 * so y calculations won't overflow
//  564 	 */
//  565 	wp = imdctWin[2];
//  566 	mOut = 0;
        MOV      R1,#+0
        STR      R1,[SP, #+4]
//  567 	for (i = 0; i < 3; i++) {
        MOV      R6,#+0
//  568 		yLo = (xPrevWin[ 0+i] << 2);
??IMDCT12x3_2:
        ADD      R0,SP,#+116
        ADD      R7,R0,R6, LSL #+2
        LDR      R0,[R7, #+0]
        LSL      R0,R0,#+2
//  569 		mOut |= FASTABS(yLo);	y[( 0+i)*NBANDS] = yLo;
        STR      R0,[SP, #+8]
        MOV      R2,R0
        ASR      R2,R2,#+31
        STR      R2,[SP, #+12]
        LDR      R1,[SP, #+188]
        ADD      R8,R1,R6, LSL #+7
        STR      R0,[R8, #+0]
//  570 		yLo = (xPrevWin[ 3+i] << 2);
        LDR      R0,[R7, #+12]
//  571 		mOut |= FASTABS(yLo);	y[( 3+i)*NBANDS] = yLo;
//  572 		yLo = (xPrevWin[ 6+i] << 2) + (MULSHIFT32(wp[0+i], xBuf[3+i]));
        ADD      R1,SP,#+44
        LSL      R0,R0,#+2
        STR      R0,[SP, #+16]
        MOV      R2,R0
        ASR      R2,R2,#+31
        STR      R2,[SP, #+20]
        STR      R0,[R8, #+384]
        LDR      R0,??DataTable4  ;; xmp3_imdctWin
        ADD      R1,R1,R6, LSL #+2
        ADD      R9,R0,R6, LSL #+2
        STR      R1,[SP, #+0]
        LDR      R1,[R1, #+12]
        LDR      R0,[R9, #+288]
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        LDR      R1,[R7, #+24]
        ADD      R0,R0,R1, LSL #+2
//  573 		mOut |= FASTABS(yLo);	y[( 6+i)*NBANDS] = yLo;
        STR      R0,[SP, #+24]
        MOV      R2,R0
        ASR      R2,R2,#+31
        STR      R2,[SP, #+28]
        STR      R0,[R8, #+768]
        MOV      R0,R6
        RSB      R0,R0,#+0
        ADD      R1,SP,#+44
        ADD      R10,R1,R0, LSL #+2
        LDR      R1,[R10, #+20]
        LDR      R0,[R9, #+300]
//  574 		yLo = (xPrevWin[ 9+i] << 2) + (MULSHIFT32(wp[3+i], xBuf[5-i]));
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        LDR      R1,[R7, #+36]
        ADD      R0,R0,R1, LSL #+2
//  575 		mOut |= FASTABS(yLo);	y[( 9+i)*NBANDS] = yLo;
        STR      R0,[SP, #+32]
        MOV      R2,R0
        ASR      R2,R2,#+31
        STR      R2,[SP, #+36]
        STR      R0,[R8, #+1152]
//  576 		yLo = (xPrevWin[12+i] << 2) + (MULSHIFT32(wp[6+i], xBuf[2-i]) + MULSHIFT32(wp[0+i], xBuf[(6+3)+i]));
        LDR      R0,[R9, #+312]
        LDR      R1,[R10, #+8]
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        MOV      R11,R0
        LDR      R0,[SP, #+0]
        LDR      R1,[R0, #+36]
        LDR      R0,[R9, #+288]
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        LDR      R1,[R7, #+48]
        ADD      R1,R11,R1, LSL #+2
        ADD      R0,R0,R1
//  577 		mOut |= FASTABS(yLo);	y[(12+i)*NBANDS] = yLo;
        STR      R0,[SP, #+0]
        MOV      R2,R0
        ASR      R2,R2,#+31
        STR      R2,[SP, #+40]
        STR      R0,[R8, #+1536]
//  578 		yLo = (xPrevWin[15+i] << 2) + (MULSHIFT32(wp[9+i], xBuf[0+i]) + MULSHIFT32(wp[3+i], xBuf[(6+5)-i]));
        ADD      R0,SP,#+44
        LDR      R1,[R0, +R6, LSL #+2]
        LDR      R0,[R9, #+324]
//  579 		mOut |= FASTABS(yLo);	y[(15+i)*NBANDS] = yLo;
//  580 	}
        ADD      R6,R6,#+1
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        LDR      R1,[R10, #+44]
        MOV      R11,R0
        LDR      R0,[R9, #+300]
        _BLF     MULSHIFT32,??MULSHIFT32??rA
        LDR      R1,[R7, #+60]
        LDR      R7,[SP, #+8]
        LDR      R9,[SP, #+12]
        LDR      R10,[SP, #+20]
        LDR      R3,[SP, #+4]
        EOR      R7,R9,R7
        SUB      R7,R7,R9
        LDR      R9,[SP, #+16]
        ADD      R1,R11,R1, LSL #+2
        EOR      R9,R10,R9
        SUB      R9,R9,R10
        LDR      R10,[SP, #+28]
        ORR      R7,R9,R7
        LDR      R9,[SP, #+24]
        ADD      R0,R0,R1
        EOR      R9,R10,R9
        SUB      R9,R9,R10
        LDR      R10,[SP, #+36]
        ORR      R7,R9,R7
        LDR      R9,[SP, #+32]
        ASR      R1,R0,#+31
        EOR      R9,R10,R9
        SUB      R9,R9,R10
        LDR      R10,[SP, #+40]
        ORR      R7,R9,R7
        LDR      R9,[SP, #+0]
        CMP      R6,#+3
        EOR      R9,R10,R9
        SUB      R9,R9,R10
        ORR      R7,R9,R7
        EOR      R9,R1,R0
        SUB      R1,R9,R1
        ORR      R1,R1,R7
        ORR      R1,R1,R3
        STR      R1,[SP, #+4]
        STR      R0,[R8, #+1920]
        BLT      ??IMDCT12x3_2
//  581 
//  582 	/* save previous (unwindowed) for overlap - only need samples 6-8, 12-17 */
//  583 	for (i = 6; i < 9; i++)
        MOV      R0,#+6
//  584 		*xPrev++ = xBuf[i] >> 2;
??IMDCT12x3_3:
        ADD      R1,SP,#+44
        LDR      R1,[R1, +R0, LSL #+2]
        ADD      R0,R0,#+1
        ASR      R1,R1,#+2
        STR      R1,[R5], #+4
        CMP      R0,#+9
        BLT      ??IMDCT12x3_3
//  585 	for (i = 12; i < 18; i++)
        MOV      R0,#+12
//  586 		*xPrev++ = xBuf[i] >> 2;
??IMDCT12x3_4:
        ADD      R1,SP,#+44
        LDR      R1,[R1, +R0, LSL #+2]
        ADD      R0,R0,#+1
        ASR      R1,R1,#+2
        STR      R1,[R5], #+4
        CMP      R0,#+18
        BLT      ??IMDCT12x3_4
//  587 
//  588 	xPrev -= 9;
//  589 	mOut |= FreqInvertRescale(y, xPrev, blockIdx, es);
        LDR      R6,[SP, #+4]
        LDR      R0,[SP, #+188]
        LDR      R2,[SP, #+228]
        MOV      R3,R4
        SUB      R1,R5,#+36
        BL       FreqInvertRescale
        ORR      R0,R0,R6
//  590 
//  591 	return mOut;
        ADD      SP,SP,#+192
        CFI CFA R13+36
        POP      {R4-R11,PC}      ;; return
        CFI EndBlock cfiBlock13
//  592 }

        RSEG CODE:CODE:NOROOT(2)
        DATA
??DataTable4:
        DC32     xmp3_imdctWin

        RSEG CODE:CODE:NOROOT(2)
        CFI Block cfiBlock14 Using cfiCommon0
        CFI NoFunction
        THUMB
??HybridTransform??rT:
        BX       PC
        Nop      
        CFI EndBlock cfiBlock14
        REQUIRE HybridTransform
//  593 
//  594 /**************************************************************************************
//  595  * Function:    HybridTransform
//  596  *
//  597  * Description: IMDCT's, windowing, and overlap-add on long/short/mixed blocks
//  598  *
//  599  * Inputs:      vector of input coefficients, length = nBlocksTotal * 18)
//  600  *              vector of overlap samples from last time, length = nBlocksPrev * 9)
//  601  *              buffer for output samples, length = MAXNSAMP
//  602  *              SideInfoSub struct for this granule/channel
//  603  *              BlockCount struct with necessary info
//  604  *                number of non-zero input and overlap blocks
//  605  *                number of long blocks in input vector (rest assumed to be short blocks)
//  606  *                number of blocks which use long window (type) 0 in case of mixed block
//  607  *                  (bc->currWinSwitch, 0 for non-mixed blocks)
//  608  *
//  609  * Outputs:     transformed, windowed, and overlapped sample buffer
//  610  *              does frequency inversion on odd blocks
//  611  *              updated buffer of samples for overlap
//  612  *
//  613  * Return:      number of non-zero IMDCT blocks calculated in this call
//  614  *                (including overlap-add)
//  615  *
//  616  * TODO:        examine mixedBlock/winSwitch logic carefully (test he_mode.bit)
//  617  **************************************************************************************/

        RSEG CODE:CODE:NOROOT(2)
        CFI Block cfiBlock15 Using cfiCommon1
        CFI Function HybridTransform
        ARM
//  618 static int HybridTransform(int *xCurr, int *xPrev, int y[BLOCK_SIZE][NBANDS], SideInfoSub *sis, BlockCount *bc)
//  619 {
HybridTransform:
        PUSH     {R4-R11,LR}
        CFI ?RET Frame(CFA, -4)
        CFI R11 Frame(CFA, -8)
        CFI R10 Frame(CFA, -12)
        CFI R9 Frame(CFA, -16)
        CFI R8 Frame(CFA, -20)
        CFI R7 Frame(CFA, -24)
        CFI R6 Frame(CFA, -28)
        CFI R5 Frame(CFA, -32)
        CFI R4 Frame(CFA, -36)
        CFI CFA R13+36
        SUB      SP,SP,#+76
        CFI CFA R13+112
        LDR      R5,[SP, #+112]
        MOV      R9,R0
//  620 	int xPrevWin[18], currWinIdx, prevWinIdx;
//  621 	int i, j, nBlocksOut, nonZero, mOut;
//  622 	int fiBit, xp;
//  623 
//  624 	ASSERT(bc->nBlocksLong  <= NBANDS);
//  625 	ASSERT(bc->nBlocksTotal <= NBANDS);
//  626 	ASSERT(bc->nBlocksPrev  <= NBANDS);
//  627 
//  628 	mOut = 0;
//  629 
//  630 	/* do long blocks, if any */
//  631 	for(i = 0; i < bc->nBlocksLong; i++) {
        LDR      R0,[R5, #+0]
        MOV      R7,R1
        MOV      R6,R2
        MOV      R10,R3
        MOV      R4,#+0
        MOV      R8,#+0
        CMP      R0,#+1
        BGE      ??HybridTransform_0
        B        ??HybridTransform_1
//  632 		/* currWinIdx picks the right window for long blocks (if mixed, long blocks use window type 0) */
//  633 		currWinIdx = sis->blockType;
//  634 		if (sis->mixedBlock && i < bc->currWinSwitch)
??HybridTransform_2:
        LDR      R0,[R10, #+24]
        LDR      R3,[R10, #+20]
        CMP      R0,#+0
        BEQ      ??HybridTransform_3
        LDR      R0,[R5, #+20]
        CMP      R8,R0
//  635 			currWinIdx = 0;
        MOVLT    R3,#+0
//  636 
//  637 		prevWinIdx = bc->prevType;
//  638 		if (i < bc->prevWinSwitch)
??HybridTransform_3:
        LDR      R0,[R5, #+16]
        LDR      R2,[R5, #+12]
        CMP      R8,R0
//  639 			 prevWinIdx = 0;
//  640 
//  641 		/* do 36-point IMDCT, including windowing and overlap-add */
//  642 		mOut |= IMDCT36(xCurr, xPrev, &(y[0][i]), currWinIdx, prevWinIdx, i, bc->gbIn);
        LDR      R0,[R5, #+24]
        MOVLT    R2,#+0
        PUSH     {R0}
        CFI CFA R13+116
        MOV      R1,R7
//  643 		xCurr += 18;
//  644 		xPrev += 9;
        ADD      R7,R7,#+36
        MOV      R0,R8
        PUSH     {R0}
        CFI CFA R13+120
        PUSH     {R2}
        CFI CFA R13+124
        ADD      R2,R6,R8, LSL #+2
        MOV      R0,R9
        ADD      R9,R9,#+72
        BL       IMDCT36
        ORR      R4,R0,R4
//  645 	}
        ADD      R8,R8,#+1
        ADD      SP,SP,#+12
        CFI CFA R13+112
??HybridTransform_0:
        LDR      R0,[R5, #+0]
        CMP      R8,R0
        BLT      ??HybridTransform_2
//  646 
//  647 	/* do short blocks (if any) */
//  648 	for (   ; i < bc->nBlocksTotal; i++) {
??HybridTransform_1:
        LDR      R0,[R5, #+4]
        CMP      R8,R0
        BGE      ??HybridTransform_4
//  649 		ASSERT(sis->blockType == 2);
//  650 
//  651 		prevWinIdx = bc->prevType;
//  652 		if (i < bc->prevWinSwitch)
        LDR      R0,[R5, #+16]
        LDR      R2,[R5, #+12]
        CMP      R8,R0
//  653 			 prevWinIdx = 0;
//  654 
//  655 		mOut |= IMDCT12x3(xCurr, xPrev, &(y[0][i]), prevWinIdx, i, bc->gbIn);
        LDR      R0,[R5, #+24]
        MOVLT    R2,#+0
        PUSH     {R0}
        CFI CFA R13+116
        MOV      R3,R2
        ADD      R2,R6,R8, LSL #+2
        MOV      R1,R7
        MOV      R0,R8
        PUSH     {R0}
        CFI CFA R13+120
//  656 		xCurr += 18;
//  657 		xPrev += 9;
        ADD      R7,R7,#+36
//  658 	}
        ADD      R8,R8,#+1
        MOV      R0,R9
        BL       IMDCT12x3
        ORR      R4,R0,R4
        ADD      R9,R9,#+72
        ADD      SP,SP,#+8
        CFI CFA R13+112
        B        ??HybridTransform_1
//  659 	nBlocksOut = i;
??HybridTransform_4:
        STR      R8,[SP, #+0]
        LDR      R0,[R5, #+8]
        MOV      R9,#+0
        CMP      R8,R0
        BGE      ??HybridTransform_5
//  660 
//  661 	/* window and overlap prev if prev longer that current */
//  662 	for (   ; i < bc->nBlocksPrev; i++) {
//  663 		prevWinIdx = bc->prevType;
??HybridTransform_6:
        LDR      R2,[R5, #+12]
//  664 		if (i < bc->prevWinSwitch)
        LDR      R0,[R5, #+16]
//  665 			 prevWinIdx = 0;
//  666 		WinPrevious(xPrev, xPrevWin, prevWinIdx);
        ADD      R1,SP,#+4
        CMP      R8,R0
        MOVLT    R2,#+0
        MOV      R0,R7
        BL       WinPrevious
//  667 
//  668 		nonZero = 0;
        MOV      LR,#+0
//  669 		fiBit = i << 31;
        LSL      R1,R8,#+31
//  670 		for (j = 0; j < 9; j++) {
        MOV      R2,R9
//  671 			xp = xPrevWin[2*j+0] << 2;	/* << 2 temp for scaling */
??HybridTransform_7:
        ADD      R0,SP,#+4
        ADD      R3,R0,R2, LSL #+3
        LDR      R0,[R3, #+0]
//  672 			nonZero |= xp;
//  673 			y[2*j+0][i] = xp;
        ADD      R12,R6,R8, LSL #+2
        LSL      R0,R0,#+2
        STR      R0,[R12, +R2, LSL #+8]
//  674 			mOut |= FASTABS(xp);
//  675 
//  676 			/* frequency inversion on odd blocks/odd samples (flip sign if i odd, j odd) */
//  677 			xp = xPrevWin[2*j+1] << 2;
//  678 			xp = (xp ^ (fiBit >> 31)) + (i & 0x01);
        LDR      R3,[R3, #+4]
        ORR      LR,R0,LR
        ASR      R10,R0,#+31
        ASR      R11,R1,#+31
        EOR      R3,R11,R3, LSL #+2
        AND      R11,R8,#0x1
        ADD      R3,R11,R3
//  679 			nonZero |= xp;
        ORR      LR,R3,LR
//  680 			y[2*j+1][i] = xp;
        ADD      R11,R12,R2, LSL #+8
        STR      R3,[R11, #+128]
//  681 			mOut |= FASTABS(xp);
        ASR      R12,R3,#+31
        EOR      R0,R10,R0
        SUB      R0,R0,R10
        EOR      R3,R12,R3
        SUB      R3,R3,R12
        ORR      R0,R3,R0
        ORR      R4,R0,R4
//  682 
//  683 			xPrev[j] = 0;
        STR      R9,[R7, +R2, LSL #+2]
//  684 		}
        ADD      R2,R2,#+1
        CMP      R2,#+9
        BLT      ??HybridTransform_7
//  685 		xPrev += 9;
//  686 		if (nonZero)
        CMP      LR,#+0
//  687 			nBlocksOut = i;
        STRNE    R8,[SP, #+0]
//  688 	}
        LDR      R0,[R5, #+8]
        ADD      R7,R7,#+36
        ADD      R8,R8,#+1
        CMP      R8,R0
        BLT      ??HybridTransform_6
//  689 
//  690 	/* clear rest of blocks */
//  691 	for (   ; i < 32; i++) {
??HybridTransform_5:
        CMP      R8,#+32
        BGE      ??HybridTransform_8
//  692 		for (j = 0; j < 18; j++)
        MOV      R2,#+0
        ADD      R0,R6,R8, LSL #+2
//  693 			y[j][i] = 0;
??HybridTransform_9:
        STR      R9,[R0, +R2, LSL #+7]
        ADD      R2,R2,#+1
        CMP      R2,#+18
        BLT      ??HybridTransform_9
//  694 	}
        ADD      R8,R8,#+1
        B        ??HybridTransform_5
//  695 
//  696 	bc->gbOut = CLZ(mOut) - 1;
??HybridTransform_8:
        CMP      R4,#+0
        MOVEQ    R0,#+32
        BEQ      ??HybridTransform_10
        MOV      R0,#+0
        TST      R4,#0x80000000
        BNE      ??HybridTransform_10
??HybridTransform_11:
        ADD      R0,R0,#+1
        LSL      R4,R4,#+1
        TST      R4,#0x80000000
        BEQ      ??HybridTransform_11
??HybridTransform_10:
        SUB      R0,R0,#+1
        STR      R0,[R5, #+28]
//  697 
//  698 	return nBlocksOut;
        LDR      R0,[SP, #+0]
        ADD      SP,SP,#+76
        CFI CFA R13+36
        POP      {R4-R11,PC}      ;; return
        CFI EndBlock cfiBlock15
//  699 }

        RSEG CODE:CODE:NOROOT(2)
        CFI Block cfiBlock16 Using cfiCommon0
        CFI NoFunction
        THUMB
??xmp3_IMDCT??rT:
        BX       PC
        Nop      
        CFI EndBlock cfiBlock16
        REQUIRE xmp3_IMDCT
//  700 
//  701 /**************************************************************************************
//  702  * Function:    IMDCT
//  703  *
//  704  * Description: do alias reduction, inverse MDCT, overlap-add, and frequency inversion
//  705  *
//  706  * Inputs:      MP3DecInfo structure filled by UnpackFrameHeader(), UnpackSideInfo(),
//  707  *                UnpackScaleFactors(), and DecodeHuffman() (for this granule, channel)
//  708  *                includes PCM samples in overBuf (from last call to IMDCT) for OLA
//  709  *              index of current granule and channel
//  710  *
//  711  * Outputs:     PCM samples in outBuf, for input to subband transform
//  712  *              PCM samples in overBuf, for OLA next time
//  713  *              updated hi->nonZeroBound index for this channel
//  714  *
//  715  * Return:      0 on success,  -1 if null input pointers
//  716  **************************************************************************************/

        RSEG CODE:CODE:NOROOT(2)
        CFI Block cfiBlock17 Using cfiCommon1
        CFI Function xmp3_IMDCT
        ARM
//  717 int IMDCT(MP3DecInfo *mp3DecInfo, int gr, int ch)
//  718 {
xmp3_IMDCT:
        PUSH     {R4-R11,LR}
        CFI ?RET Frame(CFA, -4)
        CFI R11 Frame(CFA, -8)
        CFI R10 Frame(CFA, -12)
        CFI R9 Frame(CFA, -16)
        CFI R8 Frame(CFA, -20)
        CFI R7 Frame(CFA, -24)
        CFI R6 Frame(CFA, -28)
        CFI R5 Frame(CFA, -32)
        CFI R4 Frame(CFA, -36)
        CFI CFA R13+36
        SUB      SP,SP,#+36
        CFI CFA R13+72
//  719 	int nBfly, blockCutoff;
//  720 	FrameHeader *fh;
//  721 	SideInfo *si;
//  722 	HuffmanInfo *hi;
//  723 	IMDCTInfo *mi;
//  724 	BlockCount bc;
//  725 
//  726 	/* validate pointers */
//  727 	if (!mp3DecInfo || !mp3DecInfo->FrameHeaderPS || !mp3DecInfo->SideInfoPS ||
//  728 		!mp3DecInfo->HuffmanInfoPS || !mp3DecInfo->IMDCTInfoPS)
        CMP      R0,#+0
        LDRNE    R5,[R0, #+0]
        MOV      R4,R2
        CMPNE    R5,#+0
        LDRNE    R3,[R0, #+4]
        CMPNE    R3,#+0
        LDRNE    R2,[R0, #+12]
        CMPNE    R2,#+0
        LDRNE    R0,[R0, #+20]
        CMPNE    R0,#+0
//  729 		return -1;
        MVNEQ    R0,#+0
        BEQ      ??xmp3_IMDCT_0
//  730 
//  731 	/* si is an array of up to 4 structs, stored as gr0ch0, gr0ch1, gr1ch0, gr1ch1 */
//  732 	fh = (FrameHeader *)(mp3DecInfo->FrameHeaderPS);
//  733 	si = (SideInfo *)(mp3DecInfo->SideInfoPS);
//  734 	hi = (HuffmanInfo*)(mp3DecInfo->HuffmanInfoPS);
//  735 	mi = (IMDCTInfo *)(mp3DecInfo->IMDCTInfoPS);
        STR      R0,[SP, #+0]
//  736 
//  737 	/* anti-aliasing done on whole long blocks only
//  738 	 * for mixed blocks, nBfly always 1, except 3 for 8 kHz MPEG 2.5 (see sfBandTab)
//  739      *   nLongBlocks = number of blocks with (possibly) non-zero power
//  740 	 *   nBfly = number of butterflies to do (nLongBlocks - 1, unless no long blocks)
//  741 	 */
//  742 	blockCutoff = fh->sfBand->l[(fh->ver == MPEG1 ? 8 : 6)] / 18;	/* same as 3* num short sfb's in spec */
        LDRSB    R0,[R5, #+0]
        LDR      R5,[R5, #+52]
        CMP      R0,#+0
        MOVEQ    R0,#+8
        MOVNE    R0,#+6
        ADD      R0,R5,R0, LSL #+1
        LDRSH    R0,[R0, #+0]
        LDR      R5,??xmp3_IMDCT_1  ;; 0x38e38e39
        SMULL    R6,R7,R5,R0
//  743 	if (si->sis[gr][ch].blockType != 2) {
        MOV      R5,#+4608
        ASR      R7,R7,#+2
        ADD      R11,R7,R0, LSR #+31
        ADD      R0,R2,R4, LSL #+2
        ADD      R6,R5,R0
        MOV      R0,#+72
        MOV      R7,#+144
        MLA      R1,R7,R1,R3
        MLA      R7,R0,R4,R1
        LDR      R0,[R7, #+60]
        CMP      R0,#+2
        BEQ      ??xmp3_IMDCT_2
//  744 		/* all long transforms */
//  745 		bc.nBlocksLong = MIN((hi->nonZeroBound[ch] + 7) / 18 + 1, 32);
        LDR      R0,[R6, #+0]
        LDR      R1,??xmp3_IMDCT_1  ;; 0x38e38e39
        ADD      R0,R0,#+7
        SMULL    R3,R8,R1,R0
        ASR      R8,R8,#+2
        ADD      R0,R8,R0, LSR #+31
        ADD      R0,R0,#+1
        CMP      R0,#+32
        BGE      ??xmp3_IMDCT_3
        LDR      R0,[R6, #+0]
        ADD      R0,R0,#+7
        SMULL    R3,R8,R1,R0
        ASR      R8,R8,#+2
        ADD      R0,R8,R0, LSR #+31
        ADD      R0,R0,#+1
        B        ??xmp3_IMDCT_4
??xmp3_IMDCT_3:
        MOV      R0,#+32
??xmp3_IMDCT_4:
        STR      R0,[SP, #+4]
//  746 		nBfly = bc.nBlocksLong - 1;
        SUB      R10,R0,#+1
        B        ??xmp3_IMDCT_5
//  747 	} else if (si->sis[gr][ch].blockType == 2 && si->sis[gr][ch].mixedBlock) {
??xmp3_IMDCT_2:
        BNE      ??xmp3_IMDCT_6
        LDR      R0,[R7, #+64]
        CMP      R0,#+0
//  748 		/* mixed block - long transforms until cutoff, then short transforms */
//  749 		bc.nBlocksLong = blockCutoff;
        STRNE    R11,[SP, #+4]
//  750 		nBfly = bc.nBlocksLong - 1;
        SUBNE    R10,R11,#+1
        BNE      ??xmp3_IMDCT_5
//  751 	} else {
//  752 		/* all short transforms */
//  753 		bc.nBlocksLong = 0;
??xmp3_IMDCT_6:
        MOV      R1,#+0
        STR      R1,[SP, #+4]
//  754 		nBfly = 0;
        MOV      R10,#+0
//  755 	}
//  756 
//  757 	AntiAlias(hi->huffDecBuf[ch], nBfly);
??xmp3_IMDCT_5:
        MOV      R0,#+2304
        MUL      R8,R0,R4
        MOV      R1,R10
        ADD      R9,R8,R2
        MOV      R0,R9
        BL       AntiAlias
//  758 	hi->nonZeroBound[ch] = MAX(hi->nonZeroBound[ch], (nBfly * 18) + 8);
//  759 
//  760 	ASSERT(hi->nonZeroBound[ch] <= MAX_NSAMP);
//  761 
//  762 	/* for readability, use a struct instead of passing a million parameters to HybridTransform() */
//  763 	bc.nBlocksTotal = (hi->nonZeroBound[ch] + 17) / 18;
        LDR      R2,??xmp3_IMDCT_1  ;; 0x38e38e39
        MOV      R0,#+18
        MUL      R1,R0,R10
        ADD      R0,R1,#+8
        LDR      R1,[R6, #+0]
        CMP      R0,R1
        MOVLT    R0,R1
        ADD      R1,R0,#+17
        SMULL    R3,R10,R2,R1
        STR      R0,[R6, #+0]
        ASR      R10,R10,#+2
        ADD      R1,R10,R1, LSR #+31
        STR      R1,[SP, #+8]
//  764 	bc.nBlocksPrev = mi->numPrevIMDCT[ch];
        LDR      R0,[SP, #+0]
//  765 	bc.prevType = mi->prevType[ch];
//  766 	bc.prevWinSwitch = mi->prevWinSwitch[ch];
//  767 	bc.currWinSwitch = (si->sis[gr][ch].mixedBlock ? blockCutoff : 0);	/* where WINDOW switches (not nec. transform) */
//  768 	bc.gbIn = hi->gb[ch];
//  769 
//  770 	mi->numPrevIMDCT[ch] = HybridTransform(hi->huffDecBuf[ch], mi->overBuf[ch], mi->outBuf[ch], &si->sis[gr][ch], &bc);
        ADD      R3,R7,#+40
        ADD      R0,R0,R4, LSL #+2
        ADD      R10,R0,#+6912
        LDR      R1,[R10, #+0]
        STR      R1,[SP, #+12]
        LDR      R1,[R10, #+8]
        STR      R1,[SP, #+16]
        LDR      R1,[R10, #+16]
        STR      R1,[SP, #+20]
        LDR      R0,[R7, #+64]
        CMP      R0,#+0
        MOVEQ    R11,#+0
        STR      R11,[SP, #+24]
        LDR      R1,[R6, #+8]
        ADD      R0,SP,#+4
        STR      R1,[SP, #+28]
        PUSH     {R0}
        CFI CFA R13+76
        LDR      R1,[SP, #+4]
        LDR      R0,[SP, #+4]
        ADD      R2,R8,R0
        MOV      R0,#+1152
        MLA      R1,R0,R4,R1
        MOV      R0,R9
        ADD      R1,R5,R1
        BL       HybridTransform
        STR      R0,[R10, #+0]
//  771 	mi->prevType[ch] = si->sis[gr][ch].blockType;
        LDR      R0,[R7, #+60]
        STR      R0,[R10, #+8]
//  772 	mi->prevWinSwitch[ch] = bc.currWinSwitch;		/* 0 means not a mixed block (either all short or all long) */
        LDR      R0,[SP, #+28]
        STR      R0,[R10, #+16]
//  773 	mi->gb[ch] = bc.gbOut;
        LDR      R0,[SP, #+36]
        STR      R0,[R10, #+24]
//  774 
//  775 	ASSERT(mi->numPrevIMDCT[ch] <= NBANDS);
//  776 
//  777 	/* output has gained 2 int bits */
//  778 	return 0;
        MOV      R0,#+0
        ADD      SP,SP,#+4
        CFI CFA R13+72
??xmp3_IMDCT_0:
        ADD      SP,SP,#+36       ;; stack cleaning
        CFI CFA R13+36
        POP      {R4-R11,PC}      ;; return
        DATA
??xmp3_IMDCT_1:
        DC32     0x38e38e39
        CFI EndBlock cfiBlock17
//  779 }

        RSEG CODE:CODE:NOROOT(2)
        CFI Block cfiBlock18 Using cfiCommon1
        CFI NoFunction
        ARM
??MULSHIFT32??rA:
        LDR      R12,??Subroutine9_0  ;; MULSHIFT32
        BX       R12
        DATA
??Subroutine9_0:
        DC32     MULSHIFT32
        CFI EndBlock cfiBlock18

        END
// 
// 4 968 bytes in segment CODE
//   108 bytes in segment DATA_C
// 
// 4 920 bytes of CODE  memory (+ 48 bytes shared)
//   108 bytes of CONST memory
//
//Errors: none
//Warnings: 1
